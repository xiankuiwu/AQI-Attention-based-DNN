{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras as keras\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Activation, Input, Dense, Dropout, Flatten, Conv1D, MaxPooling1D, Reshape, Concatenate, concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   AQI  PM2.5  PM10  NO2  SO2   CO  O3_8h\n0  310    260   420  139  201  3.5     13\n1  225    175   271  111  143  3.2     31\n2  275    225   360  128  197  3.9     12\n3  126     96   183   70  101  2.3     26\n4  116     88   159   70  114  1.6     16",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AQI</th>\n      <th>PM2.5</th>\n      <th>PM10</th>\n      <th>NO2</th>\n      <th>SO2</th>\n      <th>CO</th>\n      <th>O3_8h</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>310</td>\n      <td>260</td>\n      <td>420</td>\n      <td>139</td>\n      <td>201</td>\n      <td>3.5</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>225</td>\n      <td>175</td>\n      <td>271</td>\n      <td>111</td>\n      <td>143</td>\n      <td>3.2</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>275</td>\n      <td>225</td>\n      <td>360</td>\n      <td>128</td>\n      <td>197</td>\n      <td>3.9</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>126</td>\n      <td>96</td>\n      <td>183</td>\n      <td>70</td>\n      <td>101</td>\n      <td>2.3</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>116</td>\n      <td>88</td>\n      <td>159</td>\n      <td>70</td>\n      <td>114</td>\n      <td>1.6</td>\n      <td>16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取数据\n",
    "data_ini = pd.read_excel('data/TJ POLTS.xlsx')\n",
    "\n",
    "data = data_ini.iloc[:,[1,3,4,5,6,7,8]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "          AQI       PM2.5        PM10       NO2         SO2        CO  \\\n0  310.000000  260.000000  420.000000  139.0000  201.000000  3.500000   \n1  305.750000  255.750000  412.550000  137.6000  198.100000  3.485000   \n2  304.212500  254.212500  409.922500  137.1200  198.045000  3.505750   \n3  295.301875  246.301875  398.576375  133.7640  193.192750  3.445462   \n4  286.336781  238.386781  386.597556  130.5758  189.233112  3.353189   \n\n       O3_8h  \n0  13.000000  \n1  13.900000  \n2  13.805000  \n3  14.414750  \n4  14.494013  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AQI</th>\n      <th>PM2.5</th>\n      <th>PM10</th>\n      <th>NO2</th>\n      <th>SO2</th>\n      <th>CO</th>\n      <th>O3_8h</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>310.000000</td>\n      <td>260.000000</td>\n      <td>420.000000</td>\n      <td>139.0000</td>\n      <td>201.000000</td>\n      <td>3.500000</td>\n      <td>13.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>305.750000</td>\n      <td>255.750000</td>\n      <td>412.550000</td>\n      <td>137.6000</td>\n      <td>198.100000</td>\n      <td>3.485000</td>\n      <td>13.900000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>304.212500</td>\n      <td>254.212500</td>\n      <td>409.922500</td>\n      <td>137.1200</td>\n      <td>198.045000</td>\n      <td>3.505750</td>\n      <td>13.805000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>295.301875</td>\n      <td>246.301875</td>\n      <td>398.576375</td>\n      <td>133.7640</td>\n      <td>193.192750</td>\n      <td>3.445462</td>\n      <td>14.414750</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>286.336781</td>\n      <td>238.386781</td>\n      <td>386.597556</td>\n      <td>130.5758</td>\n      <td>189.233112</td>\n      <td>3.353189</td>\n      <td>14.494013</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指数平滑\n",
    "def expPreprocessing(df, alpha=0.05):\n",
    "    edata = df.ewm(alpha=alpha, adjust=False).mean()\n",
    "    return edata\n",
    "\n",
    "alpha = 0.05\n",
    "data_exp = expPreprocessing(data, alpha)\n",
    "data_exp.head()\n",
    "\n",
    "# alpha = 0.05\n",
    "# data_exp = data.ewm(alpha=alpha, adjust=False).mean()\n",
    "# data_exp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化\n",
    "min_value = data_exp.min(axis=0)  \n",
    "max_value = data_exp.max(axis=0)\n",
    "\n",
    "data_std = (data_exp - min_value) / (max_value - min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集与验证集\n",
    "\n",
    "time_stamp = 50  # 时间点长度\n",
    "ratio = 0.8\n",
    "\n",
    "split = int(ratio*len(data))\n",
    "train_data = data_std[0:split + time_stamp]\n",
    "valid_data = data_std[split - time_stamp:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column = 0 # 标签所在的列id\n",
    "forecast_horizon = 5 # 预测的步数\n",
    "x_train, y_train = [], []\n",
    "scaled_data = train_data.values\n",
    "# 训练集\n",
    "for i in range(time_stamp, len(train_data) - forecast_horizon + 1):\n",
    "    x_train.append(scaled_data[i - time_stamp:i])\n",
    "    y_train.append(scaled_data[i:i + forecast_horizon, label_column])\n",
    "\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "# 验证集\n",
    "x_valid, y_valid = [], []\n",
    "for i in range(time_stamp, len(valid_data) - forecast_horizon + 1):\n",
    "    x_valid.append(scaled_data[i - time_stamp:i])\n",
    "    y_valid.append(scaled_data[i:i + forecast_horizon, label_column])\n",
    "\n",
    "x_valid, y_valid = np.array(x_valid), np.array(y_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 贝叶斯参数优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def lstm_model(input_shape, hidden_1, hidden_2, dropout_rate):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = LSTM(hidden_1, return_sequences=True)(input_layer)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = LSTM(hidden_2)(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    output_layer = Dense(5)(x)  # 假设目标是预测一个数值\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, x_train, y_train, x_valid, y_valid, epochs=50, batch_size=64, n_trials=100):\n",
    "        self.x_train, self.y_train, self.x_valid, self.y_valid = x_train, y_train, x_valid, y_valid\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.n_trials = n_trials\n",
    "\n",
    "    def objective(self, trial):\n",
    "        lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
    "        hidden_1 = trial.suggest_int('hidden_1', 32, 256)\n",
    "        hidden_2 = trial.suggest_int('hidden_2', 32, 256)\n",
    "        dropout_rate = trial.suggest_uniform('dropout_rate', 0., 0.5)\n",
    "\n",
    "        model = lstm_model(self.x_train.shape[1:], hidden_1, hidden_2, dropout_rate)\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "        model.fit(self.x_train, self.y_train, epochs=self.epochs, batch_size=self.batch_size, verbose=0)\n",
    "\n",
    "        y_pred = model.predict(self.x_valid)\n",
    "        score = mean_squared_error(self.y_valid, y_pred)\n",
    "\n",
    "        return score\n",
    "\n",
    "    def optimizer_optuna(self):\n",
    "        sampler = optuna.samplers.TPESampler()\n",
    "        study = optuna.create_study(sampler=sampler, direction='minimize')\n",
    "        study.optimize(self.objective, n_trials=self.n_trials, show_progress_bar=True)\n",
    "        return study\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2024-01-30 11:17:58,359]\u001B[0m A new study created in memory with name: no-name-2309a10a-7a0e-461d-8063-80d4335b55ba\u001B[0m\n",
      "D:\\anaconda3\\lib\\site-packages\\optuna\\progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "42255417126641c894f44529e44f40e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2024-01-30 11:18:19,512]\u001B[0m Trial 0 finished with value: 0.0029362056150609634 and parameters: {'lr': 2.2820954054299194e-05, 'hidden_1': 34, 'hidden_2': 255, 'dropout_rate': 0.2925011049998512}. Best is trial 0 with value: 0.0029362056150609634.\u001B[0m\n",
      "\u001B[32m[I 2024-01-30 11:18:42,579]\u001B[0m Trial 1 finished with value: 0.0007114830223761614 and parameters: {'lr': 0.004425142487388236, 'hidden_1': 217, 'hidden_2': 247, 'dropout_rate': 0.029058006556695437}. Best is trial 1 with value: 0.0007114830223761614.\u001B[0m\n",
      "\u001B[32m[I 2024-01-30 11:18:58,634]\u001B[0m Trial 2 finished with value: 0.0009569572630153015 and parameters: {'lr': 0.004626786268293488, 'hidden_1': 127, 'hidden_2': 122, 'dropout_rate': 0.028234020502407253}. Best is trial 1 with value: 0.0007114830223761614.\u001B[0m\n",
      "\u001B[32m[I 2024-01-30 11:19:16,684]\u001B[0m Trial 3 finished with value: 0.0012010691655291884 and parameters: {'lr': 0.0004475851647238146, 'hidden_1': 124, 'hidden_2': 160, 'dropout_rate': 0.14865299733115445}. Best is trial 1 with value: 0.0007114830223761614.\u001B[0m\n",
      "\u001B[32m[I 2024-01-30 11:19:48,955]\u001B[0m Trial 4 finished with value: 0.0010390961754185245 and parameters: {'lr': 0.0006543963964462764, 'hidden_1': 165, 'hidden_2': 253, 'dropout_rate': 0.38250557428748067}. Best is trial 1 with value: 0.0007114830223761614.\u001B[0m\n",
      "\n",
      "{'lr': 0.004425142487388236, 'hidden_1': 217, 'hidden_2': 247, 'dropout_rate': 0.029058006556695437}\n",
      "0.0007114830223761614\n"
     ]
    }
   ],
   "source": [
    "# 超参数\n",
    "epochs = 5\n",
    "batch_size = 64\n",
    "num_heads = 4\n",
    "n_trials = 5\n",
    "#LSTM\n",
    "T = Trainer(x_train, y_train, x_valid, y_valid, epochs=epochs, batch_size=batch_size, n_trials=n_trials)\n",
    "study = T.optimizer_optuna()\n",
    "print(study.best_params)\n",
    "print(study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "41/41 [==============================] - 6s 122ms/step - loss: 0.0101\n",
      "Epoch 2/5\n",
      "41/41 [==============================] - 5s 121ms/step - loss: 0.0013\n",
      "Epoch 3/5\n",
      "41/41 [==============================] - 5s 120ms/step - loss: 0.0010\n",
      "Epoch 4/5\n",
      "41/41 [==============================] - 5s 121ms/step - loss: 0.0010\n",
      "Epoch 5/5\n",
      "41/41 [==============================] - 5s 121ms/step - loss: 9.1243e-04\n"
     ]
    }
   ],
   "source": [
    "# 根据最优超参，训练和预测\n",
    "params = study.best_params\n",
    "lr = params['lr']\n",
    "hidden_1 = params['hidden_1']\n",
    "hidden_2 = params['hidden_2']\n",
    "dropout_rate = params['dropout_rate']\n",
    "\n",
    "checkpoint_path_best = \"data/best.hdf5\"\n",
    "modelcheckpoint_best = keras.callbacks.ModelCheckpoint(checkpoint_path_best,\n",
    "                                                       monitor='loss',\n",
    "                                                       save_best_only=True,\n",
    "                                                       mode='min',\n",
    "                                                       verbose=0)\n",
    "#LSTM\n",
    "model = lstm_model(x_train.shape[1:], hidden_1, hidden_2, dropout_rate)\n",
    "\n",
    "#print(model.summary())\n",
    "model.compile(loss='mean_squared_error', optimizer=keras.optimizers.Adam(learning_rate=lr))\n",
    "model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[modelcheckpoint_best])\n",
    "\n",
    "model.load_weights(checkpoint_path_best)\n",
    "closing_price = model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0           1           2           3           4\n",
      "0    167.431957  166.060360  165.857342  169.814475  165.873751\n",
      "1    166.060360  165.857342  169.814475  165.873751  160.430063\n",
      "2    165.857342  169.814475  165.873751  160.430063  159.258560\n",
      "3    169.814475  165.873751  160.430063  159.258560  155.195632\n",
      "4    165.873751  160.430063  159.258560  155.195632  152.735850\n",
      "..          ...         ...         ...         ...         ...\n",
      "646   79.746129   78.708823   79.773382   85.684712   90.000477\n",
      "647   78.708823   79.773382   85.684712   90.000477   92.700453\n",
      "648   79.773382   85.684712   90.000477   92.700453   95.865430\n",
      "649   85.684712   90.000477   92.700453   95.865430   96.222159\n",
      "650   90.000477   92.700453   95.865430   96.222159   93.211051\n",
      "\n",
      "[651 rows x 5 columns]\n",
      "              0           1           2           3           4\n",
      "0    174.181625  175.672150  175.751999  176.079559  178.814056\n",
      "1    171.428986  172.280640  171.762131  174.222778  175.734161\n",
      "2    166.952209  167.460556  166.759277  170.571655  170.655563\n",
      "3    163.054428  163.785461  163.361465  166.924332  166.492706\n",
      "4    162.076828  163.540771  163.670364  165.389099  165.901672\n",
      "..          ...         ...         ...         ...         ...\n",
      "646   81.917923   84.097305   83.507484   84.885605   84.992783\n",
      "647   80.641754   82.934135   82.382545   83.581497   83.909767\n",
      "648   79.505783   81.881172   81.365219   82.401779   82.955811\n",
      "649   78.877548   81.364906   81.011246   81.652176   82.447388\n",
      "650   79.711319   82.400589   82.449684   82.113602   83.396744\n",
      "\n",
      "[651 rows x 5 columns]\n",
      "{'RMSE': [5.111988619235024, 5.622024858997061, 6.398332792720581, 7.676089723300745, 8.515982704744419], 'MAE': [3.659327967190701, 4.262063014706694, 4.821326166540148, 5.796165270390877, 6.576444135396831], 'R2Score': [0.9576120768441048, 0.948354907279898, 0.9326183001744689, 0.902303440036241, 0.8787431680053991], 'MAPE': [3.2153006864715854, 3.833540087452061, 4.3443699041564665, 5.262352826589227, 5.951775288415562]}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 假设 max_value, min_value, alpha, label_column 已正确定义\n",
    "# max_value = {...}\n",
    "# min_value = {...}\n",
    "# alpha = ...\n",
    "# label_column = ...\n",
    "y_valid_list = [y_valid]\n",
    "# 反归一化\n",
    "def unnormalize(data, max_value, min_value, label_column):\n",
    "    return (data * (max_value[label_column] - min_value[label_column])) + min_value[label_column]\n",
    "\n",
    "y_valid_original = unnormalize(pd.DataFrame(y_valid_list[0]), max_value, min_value, label_column)\n",
    "predictions_original = unnormalize(pd.DataFrame(closing_price), max_value, min_value, label_column)\n",
    "\n",
    "# 反平滑\n",
    "# def exp_reversed(df, alpha):\n",
    "#     reversed_df = pd.DataFrame()\n",
    "#     for column in df.columns:\n",
    "#         df_col = df[column]\n",
    "#         row_0 = df_col.iloc[0]\n",
    "#         df_t_1 = pd.Series([row_0]).append(df_col[:-1]).reset_index(drop=True)\n",
    "#         result = (df_col - (1 - alpha) * df_t_1) / alpha\n",
    "#         result.iloc[0] = df_col.iloc[0]\n",
    "#         reversed_df = pd.concat([reversed_df, result], axis=1)\n",
    "#     return reversed_df\n",
    "original_y_valid = y_valid_original\n",
    "original_predictions = predictions_original\n",
    "# original_y_valid = exp_reversed(y_valid_original, alpha)\n",
    "# original_predictions = exp_reversed(predictions_original, alpha)\n",
    "print(original_y_valid)\n",
    "print(original_predictions)\n",
    "# 评估每一步的预测\n",
    "metrics = {'RMSE': [], 'MAE': [], 'R2Score': [], 'MAPE': []}\n",
    "for step in range(5):\n",
    "    # 计算每个指标\n",
    "    rmse = np.sqrt(mean_squared_error(original_y_valid.iloc[:, step], original_predictions.iloc[:, step]))\n",
    "    mae = mean_absolute_error(original_y_valid.iloc[:, step], original_predictions.iloc[:, step])\n",
    "    r2 = r2_score(original_y_valid.iloc[:, step], original_predictions.iloc[:, step])\n",
    "    mape = np.mean(np.abs((original_y_valid.iloc[:, step] - original_predictions.iloc[:, step]) / original_y_valid.iloc[:, step])) * 100\n",
    "\n",
    "    # 存储指标\n",
    "    metrics['RMSE'].append(rmse)\n",
    "    metrics['MAE'].append(mae)\n",
    "    metrics['R2Score'].append(r2)\n",
    "    metrics['MAPE'].append(mape)\n",
    "\n",
    "# 输出指标\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RMSE': [0.0202960465943745, 0.022321039173194574, 0.02540320305218258, 0.030476261303287743, 0.03381087656771658], 'MAE': [0.014528570484688183, 0.01692160445069078, 0.019142038651957977, 0.02301242715932621, 0.026110357287719394], 'R2Score': [0.9576120902830715, 0.9483549057938678, 0.9326182962087042, 0.9023034380854192, 0.8787431581151851], 'MAPE': [7.999190168833459, 10.367227599903373, 11.72512628125177, 14.49711280204245, 16.239915898050196]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "y_valid_list = [y_valid]\n",
    "# # 假设您的模型已经产生了5步预测\n",
    "# predictions = model.predict(y_valid_list)  # 这应该是一个形状为 (n_samples, 5) 的数组\n",
    "\n",
    "# 初始化指标\n",
    "metrics = {'RMSE': [], 'MAE': [], 'R2Score': [], 'MAPE': []}\n",
    "y_valid = pd.DataFrame(y_valid_list[0])\n",
    "predictions =  pd.DataFrame(closing_price)\n",
    "# 对于每一步预测\n",
    "for step in range(5):\n",
    "    # 计算每个指标\n",
    "    rmse = np.sqrt(mean_squared_error(y_valid.iloc[:, step], predictions.iloc[:, step]))\n",
    "    mae = mean_absolute_error(y_valid.iloc[:, step], predictions.iloc[:, step])\n",
    "    r2 = r2_score(y_valid.iloc[:, step], predictions.iloc[:, step])\n",
    "    mape = np.mean(np.abs((y_valid.iloc[:, step] - predictions.iloc[:, step]) / y_valid.iloc[:, step])) * 100\n",
    "\n",
    "    # 存储指标\n",
    "    metrics['RMSE'].append(rmse)\n",
    "    metrics['MAE'].append(mae)\n",
    "    metrics['R2Score'].append(r2)\n",
    "    metrics['MAPE'].append(mape)\n",
    "\n",
    "# 输出指标\n",
    "print(metrics)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}