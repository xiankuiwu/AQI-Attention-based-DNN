{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras as keras\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Activation, Input, Dense, Dropout, Flatten, Conv1D, MaxPooling1D, Reshape, Concatenate, concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   AQI  PM2.5  PM10  NO2  SO2   CO  O3_8h\n0  310    260   420  139  201  3.5     13\n1  225    175   271  111  143  3.2     31\n2  275    225   360  128  197  3.9     12\n3  126     96   183   70  101  2.3     26\n4  116     88   159   70  114  1.6     16",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AQI</th>\n      <th>PM2.5</th>\n      <th>PM10</th>\n      <th>NO2</th>\n      <th>SO2</th>\n      <th>CO</th>\n      <th>O3_8h</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>310</td>\n      <td>260</td>\n      <td>420</td>\n      <td>139</td>\n      <td>201</td>\n      <td>3.5</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>225</td>\n      <td>175</td>\n      <td>271</td>\n      <td>111</td>\n      <td>143</td>\n      <td>3.2</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>275</td>\n      <td>225</td>\n      <td>360</td>\n      <td>128</td>\n      <td>197</td>\n      <td>3.9</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>126</td>\n      <td>96</td>\n      <td>183</td>\n      <td>70</td>\n      <td>101</td>\n      <td>2.3</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>116</td>\n      <td>88</td>\n      <td>159</td>\n      <td>70</td>\n      <td>114</td>\n      <td>1.6</td>\n      <td>16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取数据\n",
    "data_ini = pd.read_excel('data/TJ POLTS.xlsx')\n",
    "\n",
    "data = data_ini.iloc[:,[1,3,4,5,6,7,8]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "          AQI       PM2.5        PM10       NO2         SO2        CO  \\\n0  310.000000  260.000000  420.000000  139.0000  201.000000  3.500000   \n1  305.750000  255.750000  412.550000  137.6000  198.100000  3.485000   \n2  304.212500  254.212500  409.922500  137.1200  198.045000  3.505750   \n3  295.301875  246.301875  398.576375  133.7640  193.192750  3.445462   \n4  286.336781  238.386781  386.597556  130.5758  189.233112  3.353189   \n\n       O3_8h  \n0  13.000000  \n1  13.900000  \n2  13.805000  \n3  14.414750  \n4  14.494013  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AQI</th>\n      <th>PM2.5</th>\n      <th>PM10</th>\n      <th>NO2</th>\n      <th>SO2</th>\n      <th>CO</th>\n      <th>O3_8h</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>310.000000</td>\n      <td>260.000000</td>\n      <td>420.000000</td>\n      <td>139.0000</td>\n      <td>201.000000</td>\n      <td>3.500000</td>\n      <td>13.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>305.750000</td>\n      <td>255.750000</td>\n      <td>412.550000</td>\n      <td>137.6000</td>\n      <td>198.100000</td>\n      <td>3.485000</td>\n      <td>13.900000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>304.212500</td>\n      <td>254.212500</td>\n      <td>409.922500</td>\n      <td>137.1200</td>\n      <td>198.045000</td>\n      <td>3.505750</td>\n      <td>13.805000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>295.301875</td>\n      <td>246.301875</td>\n      <td>398.576375</td>\n      <td>133.7640</td>\n      <td>193.192750</td>\n      <td>3.445462</td>\n      <td>14.414750</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>286.336781</td>\n      <td>238.386781</td>\n      <td>386.597556</td>\n      <td>130.5758</td>\n      <td>189.233112</td>\n      <td>3.353189</td>\n      <td>14.494013</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指数平滑\n",
    "def expPreprocessing(df, alpha=0.05):\n",
    "    edata = df.ewm(alpha=alpha, adjust=False).mean()\n",
    "    return edata\n",
    "\n",
    "alpha = 0.05\n",
    "data_exp = expPreprocessing(data, alpha)\n",
    "data_exp.head()\n",
    "\n",
    "# alpha = 0.05\n",
    "# data_exp = data.ewm(alpha=alpha, adjust=False).mean()\n",
    "# data_exp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化\n",
    "min_value = data_exp.min(axis=0)  \n",
    "max_value = data_exp.max(axis=0)\n",
    "\n",
    "data_std = (data_exp - min_value) / (max_value - min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集与验证集\n",
    "\n",
    "time_stamp = 50  # 时间点长度\n",
    "ratio = 0.8\n",
    "\n",
    "split = int(ratio*len(data))\n",
    "train_data = data_std[0:split + time_stamp]\n",
    "valid_data = data_std[split - time_stamp:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column = 0 # 标签所在的列id\n",
    "forecast_horizon = 5 # 预测的步数\n",
    "x_train, y_train = [], []\n",
    "scaled_data = train_data.values\n",
    "# 训练集\n",
    "for i in range(time_stamp, len(train_data) - forecast_horizon + 1):\n",
    "    x_train.append(scaled_data[i - time_stamp:i])\n",
    "    y_train.append(scaled_data[i:i + forecast_horizon, label_column])\n",
    "\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "# 验证集\n",
    "x_valid, y_valid = [], []\n",
    "for i in range(time_stamp, len(valid_data) - forecast_horizon + 1):\n",
    "    x_valid.append(scaled_data[i - time_stamp:i])\n",
    "    y_valid.append(scaled_data[i:i + forecast_horizon, label_column])\n",
    "\n",
    "x_valid, y_valid = np.array(x_valid), np.array(y_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 贝叶斯参数优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, MultiHeadAttention\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import optuna\n",
    "def AutoformerBlock(input_layer, head_size, num_heads, ff_dim, dropout_rate):\n",
    "    # 自注意力层\n",
    "    attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=head_size, dropout=dropout_rate)(input_layer, input_layer)\n",
    "    attention_output = Dropout(dropout_rate)(attention_output)\n",
    "    attention_output = LayerNormalization(epsilon=1e-6)(attention_output + input_layer)\n",
    "\n",
    "    # 前馈网络\n",
    "    ffn_output = Dense(ff_dim, activation=\"relu\")(attention_output)\n",
    "    ffn_output = Dense(input_layer.shape[-1])(ffn_output)\n",
    "    ffn_output = Dropout(dropout_rate)(ffn_output)\n",
    "    ffn_output = LayerNormalization(epsilon=1e-6)(ffn_output + attention_output)\n",
    "\n",
    "    return ffn_output\n",
    "\n",
    "def autoformer_model(input_shape, head_size, num_heads, ff_dim, num_blocks, dropout_rate):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = inputs\n",
    "\n",
    "    # Autoformer块\n",
    "    for _ in range(num_blocks):\n",
    "        x = AutoformerBlock(x, head_size, num_heads, ff_dim, dropout_rate)\n",
    "\n",
    "    # 输出层\n",
    "    x = Flatten()(x)\n",
    "    outputs = Dense(5)(x)  # 假设目标是预测一个数值\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, x_train, y_train, x_valid, y_valid, epochs=50, batch_size=64, n_trials=100):\n",
    "        self.x_train, self.y_train, self.x_valid, self.y_valid = x_train, y_train, x_valid, y_valid\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.n_trials = n_trials\n",
    "    def objective(self, trial):\n",
    "        lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
    "        head_size = trial.suggest_categorical('head_size', [32, 64, 128])\n",
    "        num_heads = trial.suggest_int('num_heads', 1, 4)\n",
    "        ff_dim = trial.suggest_int('ff_dim', 32, 128)\n",
    "        num_blocks = trial.suggest_int('num_blocks', 1, 4)\n",
    "        dropout_rate = trial.suggest_uniform('dropout_rate', 0., 0.5)\n",
    "\n",
    "        model = autoformer_model(self.x_train.shape[1:], head_size, num_heads, ff_dim, num_blocks, dropout_rate)\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "        model.fit(self.x_train, self.y_train, epochs=self.epochs, batch_size=self.batch_size, verbose=0)\n",
    "\n",
    "        y_pred = model.predict(self.x_valid)\n",
    "        score = mean_squared_error(self.y_valid, y_pred)\n",
    "\n",
    "        return score\n",
    "    def optimizer_optuna(self):\n",
    "        sampler = optuna.samplers.TPESampler()\n",
    "        study = optuna.create_study(sampler=sampler, direction='minimize')\n",
    "        study.optimize(self.objective, n_trials=self.n_trials, show_progress_bar=True)\n",
    "        return study\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2024-01-30 10:44:06,718]\u001B[0m A new study created in memory with name: no-name-86792b50-7662-43f5-86a8-c9ff87684b87\u001B[0m\n",
      "D:\\anaconda3\\lib\\site-packages\\optuna\\progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a1ad53cab8e94a758bcd603f1cea435f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2024-01-30 10:44:17,807]\u001B[0m Trial 0 finished with value: 0.051278522694137164 and parameters: {'lr': 2.8486085075630468e-05, 'head_size': 64, 'num_heads': 3, 'ff_dim': 106, 'num_blocks': 1, 'dropout_rate': 0.0031560987827243814}. Best is trial 0 with value: 0.051278522694137164.\u001B[0m\n",
      "\u001B[32m[I 2024-01-30 10:44:21,704]\u001B[0m Trial 1 finished with value: 0.034906874851942285 and parameters: {'lr': 0.00020631501805454518, 'head_size': 64, 'num_heads': 1, 'ff_dim': 97, 'num_blocks': 1, 'dropout_rate': 0.3122216161480209}. Best is trial 1 with value: 0.034906874851942285.\u001B[0m\n",
      "\u001B[32m[I 2024-01-30 10:44:49,621]\u001B[0m Trial 2 finished with value: 0.00782500163307386 and parameters: {'lr': 0.002420987413505451, 'head_size': 32, 'num_heads': 4, 'ff_dim': 92, 'num_blocks': 3, 'dropout_rate': 0.420595404011426}. Best is trial 2 with value: 0.00782500163307386.\u001B[0m\n",
      "\u001B[32m[I 2024-01-30 10:45:06,426]\u001B[0m Trial 3 finished with value: 0.27481525645862526 and parameters: {'lr': 1.3174479337966132e-05, 'head_size': 128, 'num_heads': 3, 'ff_dim': 107, 'num_blocks': 1, 'dropout_rate': 0.19885261485863753}. Best is trial 2 with value: 0.00782500163307386.\u001B[0m\n",
      "\u001B[32m[I 2024-01-30 10:45:25,113]\u001B[0m Trial 4 finished with value: 0.004502747203370587 and parameters: {'lr': 0.0012503503802140498, 'head_size': 32, 'num_heads': 2, 'ff_dim': 68, 'num_blocks': 4, 'dropout_rate': 0.11757598159880983}. Best is trial 4 with value: 0.004502747203370587.\u001B[0m\n",
      "\u001B[32m[I 2024-01-30 10:45:49,237]\u001B[0m Trial 5 finished with value: 0.00687181875220221 and parameters: {'lr': 0.0001438169960707169, 'head_size': 32, 'num_heads': 3, 'ff_dim': 97, 'num_blocks': 3, 'dropout_rate': 0.2795320683973574}. Best is trial 4 with value: 0.004502747203370587.\u001B[0m\n",
      "\u001B[32m[I 2024-01-30 10:47:07,415]\u001B[0m Trial 6 finished with value: 0.047264497989752484 and parameters: {'lr': 1.8646696190535204e-05, 'head_size': 128, 'num_heads': 4, 'ff_dim': 39, 'num_blocks': 4, 'dropout_rate': 0.12792649717958332}. Best is trial 4 with value: 0.004502747203370587.\u001B[0m\n",
      "\u001B[32m[I 2024-01-30 10:47:54,825]\u001B[0m Trial 7 finished with value: 0.06150727729891523 and parameters: {'lr': 1.7474553958324042e-05, 'head_size': 128, 'num_heads': 2, 'ff_dim': 67, 'num_blocks': 4, 'dropout_rate': 0.41982347212972626}. Best is trial 4 with value: 0.004502747203370587.\u001B[0m\n",
      "\u001B[32m[I 2024-01-30 10:48:37,693]\u001B[0m Trial 8 finished with value: 0.006533631989563233 and parameters: {'lr': 8.202256006830748e-05, 'head_size': 64, 'num_heads': 3, 'ff_dim': 105, 'num_blocks': 4, 'dropout_rate': 0.14354489840910822}. Best is trial 4 with value: 0.004502747203370587.\u001B[0m\n",
      "\u001B[32m[I 2024-01-30 10:48:41,304]\u001B[0m Trial 9 finished with value: 0.020026313563366746 and parameters: {'lr': 0.0002638647938749182, 'head_size': 32, 'num_heads': 1, 'ff_dim': 72, 'num_blocks': 1, 'dropout_rate': 0.33635924729366834}. Best is trial 4 with value: 0.004502747203370587.\u001B[0m\n",
      "\n",
      "{'lr': 0.0012503503802140498, 'head_size': 32, 'num_heads': 2, 'ff_dim': 68, 'num_blocks': 4, 'dropout_rate': 0.11757598159880983}\n",
      "0.004502747203370587\n"
     ]
    }
   ],
   "source": [
    "# 超参数\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "num_heads = 4\n",
    "n_trials = 10\n",
    "\n",
    "T = Trainer(x_train, y_train, x_valid, y_valid, epochs=epochs, batch_size=batch_size, n_trials=n_trials)\n",
    "study = T.optimizer_optuna()\n",
    "print(study.best_params)\n",
    "print(study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "41/41 [==============================] - 3s 49ms/step - loss: 0.1502\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.0255\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 2s 47ms/step - loss: 0.0176\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 2s 48ms/step - loss: 0.0133\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 2s 48ms/step - loss: 0.0112\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 2s 47ms/step - loss: 0.0098\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 2s 48ms/step - loss: 0.0091\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 2s 48ms/step - loss: 0.0078\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.0074\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.0068\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 2s 47ms/step - loss: 0.0065\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.0063\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 2s 48ms/step - loss: 0.0063\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 2s 51ms/step - loss: 0.0060\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 2s 49ms/step - loss: 0.0055\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.0056\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.0053\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 2s 51ms/step - loss: 0.0055\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 2s 49ms/step - loss: 0.0048\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.0050\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.0048\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.0047\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.0048\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.0044\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.0042\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.0040\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.0040\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.0036\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.0037\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.0040\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.0035\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.0033\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.0032\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 2s 47ms/step - loss: 0.0031\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.0029\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.0030\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.0027\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 2s 47ms/step - loss: 0.0026\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 2s 47ms/step - loss: 0.0027\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.0026\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.0024\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 2s 47ms/step - loss: 0.0025\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 2s 48ms/step - loss: 0.0022\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - 2s 47ms/step - loss: 0.0025\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - 2s 47ms/step - loss: 0.0020\n",
      "Epoch 46/50\n",
      "41/41 [==============================] - 2s 47ms/step - loss: 0.0021\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.0020\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - 2s 47ms/step - loss: 0.0021\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 0.0019\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - 2s 47ms/step - loss: 0.0020\n"
     ]
    }
   ],
   "source": [
    "# 根据最优超参，训练和预测\n",
    "params = study.best_params\n",
    "lr = params['lr']\n",
    "head_size = params['head_size']\n",
    "num_heads = params['num_heads']\n",
    "ff_dim = params['ff_dim']\n",
    "num_blocks = params['num_blocks']\n",
    "dropout_rate = params['dropout_rate']\n",
    "checkpoint_path_best = \"data/best.hdf5\"\n",
    "modelcheckpoint_best = keras.callbacks.ModelCheckpoint(checkpoint_path_best,\n",
    "                                                       monitor='loss',\n",
    "                                                       save_best_only=True,\n",
    "                                                       mode='min',\n",
    "                                                       verbose=0)\n",
    "#LSTM\n",
    "\n",
    "model = autoformer_model(x_train.shape[1:], head_size, num_heads, ff_dim, num_blocks, dropout_rate)\n",
    "\n",
    "#print(model.summary())\n",
    "model.compile(loss='mean_squared_error', optimizer=keras.optimizers.Adam(learning_rate=lr))\n",
    "model.fit(x_train, y_train, epochs=50, batch_size=batch_size, verbose=1, callbacks=[modelcheckpoint_best])\n",
    "\n",
    "model.load_weights(checkpoint_path_best)\n",
    "closing_price = model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0           1           2           3           4\n",
      "0    167.431957  166.060360  165.857342  169.814475  165.873751\n",
      "1    166.060360  165.857342  169.814475  165.873751  160.430063\n",
      "2    165.857342  169.814475  165.873751  160.430063  159.258560\n",
      "3    169.814475  165.873751  160.430063  159.258560  155.195632\n",
      "4    165.873751  160.430063  159.258560  155.195632  152.735850\n",
      "..          ...         ...         ...         ...         ...\n",
      "646   79.746129   78.708823   79.773382   85.684712   90.000477\n",
      "647   78.708823   79.773382   85.684712   90.000477   92.700453\n",
      "648   79.773382   85.684712   90.000477   92.700453   95.865430\n",
      "649   85.684712   90.000477   92.700453   95.865430   96.222159\n",
      "650   90.000477   92.700453   95.865430   96.222159   93.211051\n",
      "\n",
      "[651 rows x 5 columns]\n",
      "              0           1           2           3           4\n",
      "0    136.793793  137.840393  133.042374  134.314774  131.829178\n",
      "1    137.167664  138.900345  132.732086  135.728485  131.794525\n",
      "2    137.537079  138.879486  133.173569  135.630692  131.716599\n",
      "3    137.955246  139.063065  134.605209  136.598160  131.898727\n",
      "4    137.650223  139.424881  135.064804  138.352921  132.535278\n",
      "..          ...         ...         ...         ...         ...\n",
      "646   76.454445   77.793861   76.893822   74.964958   76.500610\n",
      "647   76.318634   77.485977   77.332733   74.712906   76.408546\n",
      "648   76.027237   77.811401   77.265854   74.285187   76.199760\n",
      "649   75.789062   78.064331   76.868973   74.114227   76.174286\n",
      "650   75.589539   79.166122   77.146347   74.711708   76.260117\n",
      "\n",
      "[651 rows x 5 columns]\n",
      "{'RMSE': [10.29697857796993, 9.461717888934707, 10.808588032426849, 11.696549201096621, 11.212567987255845], 'MAE': [7.982403943694342, 7.144799343980577, 8.041509890972714, 8.894947066004928, 8.414563273201571], 'R2Score': [0.8280183939757382, 0.8537204794618165, 0.8077146306701742, 0.7731625842011622, 0.789793154582149], 'MAPE': [6.902647609498307, 6.178384725544363, 6.950488126924884, 7.704919211625719, 7.302499229828186]}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 假设 max_value, min_value, alpha, label_column 已正确定义\n",
    "# max_value = {...}\n",
    "# min_value = {...}\n",
    "# alpha = ...\n",
    "# label_column = ...\n",
    "y_valid_list = [y_valid]\n",
    "# 反归一化\n",
    "def unnormalize(data, max_value, min_value, label_column):\n",
    "    return (data * (max_value[label_column] - min_value[label_column])) + min_value[label_column]\n",
    "\n",
    "y_valid_original = unnormalize(pd.DataFrame(y_valid_list[0]), max_value, min_value, label_column)\n",
    "predictions_original = unnormalize(pd.DataFrame(closing_price), max_value, min_value, label_column)\n",
    "\n",
    "# 反平滑\n",
    "# def exp_reversed(df, alpha):\n",
    "#     reversed_df = pd.DataFrame()\n",
    "#     for column in df.columns:\n",
    "#         df_col = df[column]\n",
    "#         row_0 = df_col.iloc[0]\n",
    "#         df_t_1 = pd.Series([row_0]).append(df_col[:-1]).reset_index(drop=True)\n",
    "#         result = (df_col - (1 - alpha) * df_t_1) / alpha\n",
    "#         result.iloc[0] = df_col.iloc[0]\n",
    "#         reversed_df = pd.concat([reversed_df, result], axis=1)\n",
    "#     return reversed_df\n",
    "original_y_valid = y_valid_original\n",
    "original_predictions = predictions_original\n",
    "# original_y_valid = exp_reversed(y_valid_original, alpha)\n",
    "# original_predictions = exp_reversed(predictions_original, alpha)\n",
    "print(original_y_valid)\n",
    "print(original_predictions)\n",
    "# 评估每一步的预测\n",
    "metrics = {'RMSE': [], 'MAE': [], 'R2Score': [], 'MAPE': []}\n",
    "for step in range(5):\n",
    "    # 计算每个指标\n",
    "    rmse = np.sqrt(mean_squared_error(original_y_valid.iloc[:, step], original_predictions.iloc[:, step]))\n",
    "    mae = mean_absolute_error(original_y_valid.iloc[:, step], original_predictions.iloc[:, step])\n",
    "    r2 = r2_score(original_y_valid.iloc[:, step], original_predictions.iloc[:, step])\n",
    "    mape = np.mean(np.abs((original_y_valid.iloc[:, step] - original_predictions.iloc[:, step]) / original_y_valid.iloc[:, step])) * 100\n",
    "\n",
    "    # 存储指标\n",
    "    metrics['RMSE'].append(rmse)\n",
    "    metrics['MAE'].append(mae)\n",
    "    metrics['R2Score'].append(r2)\n",
    "    metrics['MAPE'].append(mape)\n",
    "\n",
    "# 输出指标\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RMSE': [0.040881930131851985, 0.03756570905896921, 0.042913166130231155, 0.04643862486444115, 0.04451708163003778], 'MAE': [0.031692410998595134, 0.028366884347701817, 0.03192707871931319, 0.03531546729009005, 0.03340820741609878], 'R2Score': [0.8280184409859999, 0.8537205105341432, 0.8077146731432456, 0.7731626289418655, 0.7897931984263525], 'MAPE': [17.759048491415136, 17.3916805468904, 18.818959885733307, 19.65733405779114, 19.875580489566754]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "y_valid_list = [y_valid]\n",
    "# # 假设您的模型已经产生了5步预测\n",
    "# predictions = model.predict(y_valid_list)  # 这应该是一个形状为 (n_samples, 5) 的数组\n",
    "\n",
    "# 初始化指标\n",
    "metrics = {'RMSE': [], 'MAE': [], 'R2Score': [], 'MAPE': []}\n",
    "y_valid = pd.DataFrame(y_valid_list[0])\n",
    "predictions =  pd.DataFrame(closing_price)\n",
    "# 对于每一步预测\n",
    "for step in range(5):\n",
    "    # 计算每个指标\n",
    "    rmse = np.sqrt(mean_squared_error(y_valid.iloc[:, step], predictions.iloc[:, step]))\n",
    "    mae = mean_absolute_error(y_valid.iloc[:, step], predictions.iloc[:, step])\n",
    "    r2 = r2_score(y_valid.iloc[:, step], predictions.iloc[:, step])\n",
    "    mape = np.mean(np.abs((y_valid.iloc[:, step] - predictions.iloc[:, step]) / y_valid.iloc[:, step])) * 100\n",
    "\n",
    "    # 存储指标\n",
    "    metrics['RMSE'].append(rmse)\n",
    "    metrics['MAE'].append(mae)\n",
    "    metrics['R2Score'].append(r2)\n",
    "    metrics['MAPE'].append(mape)\n",
    "\n",
    "# 输出指标\n",
    "print(metrics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}