{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras as keras\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Activation, Input, Dense, Dropout, Flatten, Conv1D, MaxPooling1D, Reshape, Concatenate, concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   AQI  PM2.5  PM10  NO2  SO2   CO  O3_8h\n0  310    260   420  139  201  3.5     13\n1  225    175   271  111  143  3.2     31\n2  275    225   360  128  197  3.9     12\n3  126     96   183   70  101  2.3     26\n4  116     88   159   70  114  1.6     16",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AQI</th>\n      <th>PM2.5</th>\n      <th>PM10</th>\n      <th>NO2</th>\n      <th>SO2</th>\n      <th>CO</th>\n      <th>O3_8h</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>310</td>\n      <td>260</td>\n      <td>420</td>\n      <td>139</td>\n      <td>201</td>\n      <td>3.5</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>225</td>\n      <td>175</td>\n      <td>271</td>\n      <td>111</td>\n      <td>143</td>\n      <td>3.2</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>275</td>\n      <td>225</td>\n      <td>360</td>\n      <td>128</td>\n      <td>197</td>\n      <td>3.9</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>126</td>\n      <td>96</td>\n      <td>183</td>\n      <td>70</td>\n      <td>101</td>\n      <td>2.3</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>116</td>\n      <td>88</td>\n      <td>159</td>\n      <td>70</td>\n      <td>114</td>\n      <td>1.6</td>\n      <td>16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取数据\n",
    "data_ini = pd.read_excel('data/TJ POLTS.xlsx')\n",
    "\n",
    "data = data_ini.iloc[:,[1,3,4,5,6,7,8]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "          AQI       PM2.5        PM10       NO2         SO2        CO  \\\n0  310.000000  260.000000  420.000000  139.0000  201.000000  3.500000   \n1  305.750000  255.750000  412.550000  137.6000  198.100000  3.485000   \n2  304.212500  254.212500  409.922500  137.1200  198.045000  3.505750   \n3  295.301875  246.301875  398.576375  133.7640  193.192750  3.445462   \n4  286.336781  238.386781  386.597556  130.5758  189.233112  3.353189   \n\n       O3_8h  \n0  13.000000  \n1  13.900000  \n2  13.805000  \n3  14.414750  \n4  14.494013  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AQI</th>\n      <th>PM2.5</th>\n      <th>PM10</th>\n      <th>NO2</th>\n      <th>SO2</th>\n      <th>CO</th>\n      <th>O3_8h</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>310.000000</td>\n      <td>260.000000</td>\n      <td>420.000000</td>\n      <td>139.0000</td>\n      <td>201.000000</td>\n      <td>3.500000</td>\n      <td>13.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>305.750000</td>\n      <td>255.750000</td>\n      <td>412.550000</td>\n      <td>137.6000</td>\n      <td>198.100000</td>\n      <td>3.485000</td>\n      <td>13.900000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>304.212500</td>\n      <td>254.212500</td>\n      <td>409.922500</td>\n      <td>137.1200</td>\n      <td>198.045000</td>\n      <td>3.505750</td>\n      <td>13.805000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>295.301875</td>\n      <td>246.301875</td>\n      <td>398.576375</td>\n      <td>133.7640</td>\n      <td>193.192750</td>\n      <td>3.445462</td>\n      <td>14.414750</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>286.336781</td>\n      <td>238.386781</td>\n      <td>386.597556</td>\n      <td>130.5758</td>\n      <td>189.233112</td>\n      <td>3.353189</td>\n      <td>14.494013</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指数平滑\n",
    "def expPreprocessing(df, alpha=0.05):\n",
    "    edata = df.ewm(alpha=alpha, adjust=False).mean()\n",
    "    return edata\n",
    "\n",
    "alpha = 0.05\n",
    "data_exp = expPreprocessing(data, alpha)\n",
    "data_exp.head()\n",
    "\n",
    "# alpha = 0.05\n",
    "# data_exp = data.ewm(alpha=alpha, adjust=False).mean()\n",
    "# data_exp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化\n",
    "min_value = data_exp.min(axis=0)  \n",
    "max_value = data_exp.max(axis=0)\n",
    "\n",
    "data_std = (data_exp - min_value) / (max_value - min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集与验证集\n",
    "\n",
    "time_stamp = 50  # 时间点长度\n",
    "ratio = 0.8\n",
    "\n",
    "split = int(ratio*len(data))\n",
    "train_data = data_std[0:split + time_stamp]\n",
    "valid_data = data_std[split - time_stamp:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column = 0 # 标签所在的列id\n",
    "forecast_horizon = 5 # 预测的步数\n",
    "x_train, y_train = [], []\n",
    "scaled_data = train_data.values\n",
    "# 训练集\n",
    "for i in range(time_stamp, len(train_data) - forecast_horizon + 1):\n",
    "    x_train.append(scaled_data[i - time_stamp:i])\n",
    "    y_train.append(scaled_data[i:i + forecast_horizon, label_column])\n",
    "\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "# 验证集\n",
    "x_valid, y_valid = [], []\n",
    "for i in range(time_stamp, len(valid_data) - forecast_horizon + 1):\n",
    "    x_valid.append(scaled_data[i - time_stamp:i])\n",
    "    y_valid.append(scaled_data[i:i + forecast_horizon, label_column])\n",
    "\n",
    "x_valid, y_valid = np.array(x_valid), np.array(y_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 贝叶斯参数优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Concatenate, Flatten\n",
    "import optuna\n",
    "def n_beats_block(input_layer, units, backcast_length, forecast_length):\n",
    "    x = Dense(units, activation='relu')(input_layer)\n",
    "    x = Dense(units, activation='relu')(x)\n",
    "    backcast = Dense(backcast_length)(x)\n",
    "    forecast = Dense(forecast_length)(x)\n",
    "    return backcast, forecast\n",
    "\n",
    "def n_beats_model(input_shape, num_blocks, units, backcast_length, forecast_length):\n",
    "    x_input = Input(shape=input_shape)\n",
    "    forecasts = []\n",
    "    backcasts = []\n",
    "    x = x_input\n",
    "\n",
    "    for _ in range(num_blocks):\n",
    "        backcast, forecast = n_beats_block(x, units, backcast_length, forecast_length)\n",
    "        forecasts.append(forecast)\n",
    "        backcasts.append(backcast)\n",
    "        x = Concatenate()([x, backcast])\n",
    "\n",
    "    final_output = Dense(forecast_length)(Flatten()(Concatenate()(forecasts)))\n",
    "    return Model(inputs=x_input, outputs=final_output)\n",
    "\n",
    "# 更新 Trainer 类中的模型创建函数\n",
    "class Trainer:\n",
    "\n",
    "    def __init__(self, x_train, y_train, x_valid, y_valid, epochs=50, batch_size=64, n_trials=100):\n",
    "        self.x_train, self.y_train, self.x_valid, self.y_valid = x_train, y_train, x_valid, y_valid\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.n_trials = n_trials\n",
    "    def objective(self, trial):\n",
    "        lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
    "        units = trial.suggest_int('units', 32, 256)\n",
    "        num_blocks = trial.suggest_int('num_blocks', 1, 5)\n",
    "        # 检查 y_train 是否是一维的，如果是，设置 forecast_length 为 1\n",
    "        forecast_length = 5\n",
    "        backcast_length = self.x_train.shape[1]\n",
    "\n",
    "        model = n_beats_model(self.x_train.shape[1:], num_blocks, units, backcast_length, forecast_length)\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "        model.fit(self.x_train, self.y_train, epochs=self.epochs, batch_size=self.batch_size, verbose=0)\n",
    "\n",
    "        y_pred = model.predict(self.x_valid)\n",
    "        score = mean_squared_error(self.y_valid, y_pred)\n",
    "\n",
    "        return score\n",
    "\n",
    "    def optimizer_optuna(self):\n",
    "        sampler = optuna.samplers.TPESampler()\n",
    "        study = optuna.create_study(sampler=sampler, direction='minimize')\n",
    "        study.optimize(self.objective, n_trials=self.n_trials, show_progress_bar=True)\n",
    "        return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2024-01-30 11:25:46,013]\u001B[0m A new study created in memory with name: no-name-ed32a6b4-1cd1-4b15-ae9a-bb9fd569c5cf\u001B[0m\n",
      "D:\\anaconda3\\lib\\site-packages\\optuna\\progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3a82fcc58d28486bb9baa2b45b4cb2d5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2024-01-30 11:25:47,463]\u001B[0m Trial 0 finished with value: 0.001484754430920907 and parameters: {'lr': 0.0002760562679880943, 'units': 194, 'num_blocks': 1}. Best is trial 0 with value: 0.001484754430920907.\u001B[0m\n",
      "\u001B[32m[I 2024-01-30 11:25:49,886]\u001B[0m Trial 1 finished with value: 0.010646782094816027 and parameters: {'lr': 1.241675908666818e-05, 'units': 172, 'num_blocks': 2}. Best is trial 0 with value: 0.001484754430920907.\u001B[0m\n",
      "\u001B[32m[I 2024-01-30 11:25:50,492]\u001B[0m Trial 2 finished with value: 0.0013712121334402932 and parameters: {'lr': 0.0022809137228509105, 'units': 53, 'num_blocks': 1}. Best is trial 2 with value: 0.0013712121334402932.\u001B[0m\n",
      "\u001B[32m[I 2024-01-30 11:25:53,755]\u001B[0m Trial 3 finished with value: 0.0006722190506197811 and parameters: {'lr': 0.0007866178334794188, 'units': 141, 'num_blocks': 3}. Best is trial 3 with value: 0.0006722190506197811.\u001B[0m\n",
      "\u001B[32m[I 2024-01-30 11:25:54,709]\u001B[0m Trial 4 finished with value: 0.0015248005511967308 and parameters: {'lr': 0.0018529325040483537, 'units': 128, 'num_blocks': 1}. Best is trial 3 with value: 0.0006722190506197811.\u001B[0m\n",
      "\n",
      "{'lr': 0.0007866178334794188, 'units': 141, 'num_blocks': 3}\n",
      "0.0006722190506197811\n"
     ]
    }
   ],
   "source": [
    "# 超参数\n",
    "epochs = 5\n",
    "batch_size = 64\n",
    "num_heads = 4\n",
    "n_trials = 5\n",
    "# 使用 N-BEATS\n",
    "T = Trainer(x_train, y_train, x_valid, y_valid, epochs=epochs, batch_size=batch_size, n_trials=n_trials)\n",
    "study = T.optimizer_optuna()\n",
    "print(study.best_params)\n",
    "print(study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.0057\n",
      "Epoch 2/5\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0015\n",
      "Epoch 3/5\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0012\n",
      "Epoch 4/5\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0010\n",
      "Epoch 5/5\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 9.0652e-04\n"
     ]
    }
   ],
   "source": [
    "# 根据最优超参，训练和预测\n",
    "params = study.best_params\n",
    "lr = params['lr']\n",
    "units = params['units']\n",
    "num_blocks = params['num_blocks']\n",
    "\n",
    "checkpoint_path_best = \"data/best.hdf5\"\n",
    "modelcheckpoint_best = keras.callbacks.ModelCheckpoint(checkpoint_path_best,\n",
    "                                                       monitor='loss',\n",
    "                                                       save_best_only=True,\n",
    "                                                       mode='min',\n",
    "                                                       verbose=0)\n",
    "#LSTM\n",
    "forecast_length = 1 if len(y_train.shape) == 1 else y_train.shape[1]\n",
    "backcast_length = x_train.shape[1]\n",
    "model = n_beats_model(x_train.shape[1:], num_blocks, units, backcast_length, forecast_length)\n",
    "\n",
    "#print(model.summary())\n",
    "model.compile(loss='mean_squared_error', optimizer=keras.optimizers.Adam(learning_rate=lr))\n",
    "model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[modelcheckpoint_best])\n",
    "\n",
    "model.load_weights(checkpoint_path_best)\n",
    "closing_price = model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0           1           2           3           4\n",
      "0    167.431957  166.060360  165.857342  169.814475  165.873751\n",
      "1    166.060360  165.857342  169.814475  165.873751  160.430063\n",
      "2    165.857342  169.814475  165.873751  160.430063  159.258560\n",
      "3    169.814475  165.873751  160.430063  159.258560  155.195632\n",
      "4    165.873751  160.430063  159.258560  155.195632  152.735850\n",
      "..          ...         ...         ...         ...         ...\n",
      "646   79.746129   78.708823   79.773382   85.684712   90.000477\n",
      "647   78.708823   79.773382   85.684712   90.000477   92.700453\n",
      "648   79.773382   85.684712   90.000477   92.700453   95.865430\n",
      "649   85.684712   90.000477   92.700453   95.865430   96.222159\n",
      "650   90.000477   92.700453   95.865430   96.222159   93.211051\n",
      "\n",
      "[651 rows x 5 columns]\n",
      "              0           1           2           3           4\n",
      "0    152.009293  149.848633  146.986908  143.807755  133.199341\n",
      "1    153.303299  151.435272  145.061478  142.076675  134.454681\n",
      "2    152.174866  147.948868  143.595764  143.497772  133.251724\n",
      "3    150.434174  147.767410  146.271713  145.860794  137.758652\n",
      "4    150.565186  150.588928  144.843170  143.766617  137.406876\n",
      "..          ...         ...         ...         ...         ...\n",
      "646   85.685532   86.000359   86.218285   88.738777   83.935272\n",
      "647   84.572235   84.456032   86.793365   89.597481   82.913635\n",
      "648   83.668854   82.930351   86.413490   88.076790   82.325974\n",
      "649   82.803078   82.833687   87.644958   86.734711   82.576385\n",
      "650   83.664764   84.859612   89.558479   86.204254   84.295738\n",
      "\n",
      "[651 rows x 5 columns]\n",
      "{'RMSE': [6.683884504403598, 7.090648814779318, 7.927992280869656, 7.8874051479746266, 9.135676149375373], 'MAE': [4.946250368348805, 5.446062524567932, 5.801548937114621, 5.758142880533095, 6.7021395593196305], 'R2Score': [0.9275363417113215, 0.9178485013150017, 0.8965489864870918, 0.8968504147338611, 0.8604537829485744], 'MAPE': [4.409572211284696, 4.8259632205180445, 5.1180843598875105, 5.119959708315513, 5.901452119081265]}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 假设 max_value, min_value, alpha, label_column 已正确定义\n",
    "# max_value = {...}\n",
    "# min_value = {...}\n",
    "# alpha = ...\n",
    "# label_column = ...\n",
    "y_valid_list = [y_valid]\n",
    "# 反归一化\n",
    "def unnormalize(data, max_value, min_value, label_column):\n",
    "    return (data * (max_value[label_column] - min_value[label_column])) + min_value[label_column]\n",
    "\n",
    "y_valid_original = unnormalize(pd.DataFrame(y_valid_list[0]), max_value, min_value, label_column)\n",
    "predictions_original = unnormalize(pd.DataFrame(closing_price), max_value, min_value, label_column)\n",
    "\n",
    "# 反平滑\n",
    "# def exp_reversed(df, alpha):\n",
    "#     reversed_df = pd.DataFrame()\n",
    "#     for column in df.columns:\n",
    "#         df_col = df[column]\n",
    "#         row_0 = df_col.iloc[0]\n",
    "#         df_t_1 = pd.Series([row_0]).append(df_col[:-1]).reset_index(drop=True)\n",
    "#         result = (df_col - (1 - alpha) * df_t_1) / alpha\n",
    "#         result.iloc[0] = df_col.iloc[0]\n",
    "#         reversed_df = pd.concat([reversed_df, result], axis=1)\n",
    "#     return reversed_df\n",
    "original_y_valid = y_valid_original\n",
    "original_predictions = predictions_original\n",
    "# original_y_valid = exp_reversed(y_valid_original, alpha)\n",
    "# original_predictions = exp_reversed(predictions_original, alpha)\n",
    "print(original_y_valid)\n",
    "print(original_predictions)\n",
    "# 评估每一步的预测\n",
    "metrics = {'RMSE': [], 'MAE': [], 'R2Score': [], 'MAPE': []}\n",
    "for step in range(5):\n",
    "    # 计算每个指标\n",
    "    rmse = np.sqrt(mean_squared_error(original_y_valid.iloc[:, step], original_predictions.iloc[:, step]))\n",
    "    mae = mean_absolute_error(original_y_valid.iloc[:, step], original_predictions.iloc[:, step])\n",
    "    r2 = r2_score(original_y_valid.iloc[:, step], original_predictions.iloc[:, step])\n",
    "    mape = np.mean(np.abs((original_y_valid.iloc[:, step] - original_predictions.iloc[:, step]) / original_y_valid.iloc[:, step])) * 100\n",
    "\n",
    "    # 存储指标\n",
    "    metrics['RMSE'].append(rmse)\n",
    "    metrics['MAE'].append(mae)\n",
    "    metrics['R2Score'].append(r2)\n",
    "    metrics['MAPE'].append(mape)\n",
    "\n",
    "# 输出指标\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RMSE': [0.026536920351993187, 0.028151889132663574, 0.03147638439179759, 0.031315240808861756, 0.03627123031051915], 'MAE': [0.019638018886597313, 0.021622413440096775, 0.023033800088609547, 0.022861465075262124, 0.026609398495977182], 'R2Score': [0.9275363609506411, 0.9178485294992376, 0.8965489960722894, 0.8968504316743989, 0.8604538155196473], 'MAPE': [12.247822892619142, 12.787381231037582, 14.132187143402527, 14.545040905425946, 16.467099124632732]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "y_valid_list = [y_valid]\n",
    "# # 假设您的模型已经产生了5步预测\n",
    "# predictions = model.predict(y_valid_list)  # 这应该是一个形状为 (n_samples, 5) 的数组\n",
    "\n",
    "# 初始化指标\n",
    "metrics = {'RMSE': [], 'MAE': [], 'R2Score': [], 'MAPE': []}\n",
    "y_valid = pd.DataFrame(y_valid_list[0])\n",
    "predictions =  pd.DataFrame(closing_price)\n",
    "# 对于每一步预测\n",
    "for step in range(5):\n",
    "    # 计算每个指标\n",
    "    rmse = np.sqrt(mean_squared_error(y_valid.iloc[:, step], predictions.iloc[:, step]))\n",
    "    mae = mean_absolute_error(y_valid.iloc[:, step], predictions.iloc[:, step])\n",
    "    r2 = r2_score(y_valid.iloc[:, step], predictions.iloc[:, step])\n",
    "    mape = np.mean(np.abs((y_valid.iloc[:, step] - predictions.iloc[:, step]) / y_valid.iloc[:, step])) * 100\n",
    "\n",
    "    # 存储指标\n",
    "    metrics['RMSE'].append(rmse)\n",
    "    metrics['MAE'].append(mae)\n",
    "    metrics['R2Score'].append(r2)\n",
    "    metrics['MAPE'].append(mape)\n",
    "\n",
    "# 输出指标\n",
    "print(metrics)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}