{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras as keras\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Activation, Input, Dense, Dropout, Flatten, Conv1D, MaxPooling1D, Reshape, Concatenate, concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   AQI  PM2.5  PM10  NO2  SO2   CO  O3_8h\n0  310    260   420  139  201  3.5     13\n1  225    175   271  111  143  3.2     31\n2  275    225   360  128  197  3.9     12\n3  126     96   183   70  101  2.3     26\n4  116     88   159   70  114  1.6     16",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AQI</th>\n      <th>PM2.5</th>\n      <th>PM10</th>\n      <th>NO2</th>\n      <th>SO2</th>\n      <th>CO</th>\n      <th>O3_8h</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>310</td>\n      <td>260</td>\n      <td>420</td>\n      <td>139</td>\n      <td>201</td>\n      <td>3.5</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>225</td>\n      <td>175</td>\n      <td>271</td>\n      <td>111</td>\n      <td>143</td>\n      <td>3.2</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>275</td>\n      <td>225</td>\n      <td>360</td>\n      <td>128</td>\n      <td>197</td>\n      <td>3.9</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>126</td>\n      <td>96</td>\n      <td>183</td>\n      <td>70</td>\n      <td>101</td>\n      <td>2.3</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>116</td>\n      <td>88</td>\n      <td>159</td>\n      <td>70</td>\n      <td>114</td>\n      <td>1.6</td>\n      <td>16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取数据\n",
    "data_ini = pd.read_excel('data/TJ POLTS.xlsx')\n",
    "\n",
    "data = data_ini.iloc[:,[1,3,4,5,6,7,8]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "          AQI       PM2.5        PM10       NO2         SO2        CO  \\\n0  310.000000  260.000000  420.000000  139.0000  201.000000  3.500000   \n1  305.750000  255.750000  412.550000  137.6000  198.100000  3.485000   \n2  304.212500  254.212500  409.922500  137.1200  198.045000  3.505750   \n3  295.301875  246.301875  398.576375  133.7640  193.192750  3.445462   \n4  286.336781  238.386781  386.597556  130.5758  189.233112  3.353189   \n\n       O3_8h  \n0  13.000000  \n1  13.900000  \n2  13.805000  \n3  14.414750  \n4  14.494013  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AQI</th>\n      <th>PM2.5</th>\n      <th>PM10</th>\n      <th>NO2</th>\n      <th>SO2</th>\n      <th>CO</th>\n      <th>O3_8h</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>310.000000</td>\n      <td>260.000000</td>\n      <td>420.000000</td>\n      <td>139.0000</td>\n      <td>201.000000</td>\n      <td>3.500000</td>\n      <td>13.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>305.750000</td>\n      <td>255.750000</td>\n      <td>412.550000</td>\n      <td>137.6000</td>\n      <td>198.100000</td>\n      <td>3.485000</td>\n      <td>13.900000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>304.212500</td>\n      <td>254.212500</td>\n      <td>409.922500</td>\n      <td>137.1200</td>\n      <td>198.045000</td>\n      <td>3.505750</td>\n      <td>13.805000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>295.301875</td>\n      <td>246.301875</td>\n      <td>398.576375</td>\n      <td>133.7640</td>\n      <td>193.192750</td>\n      <td>3.445462</td>\n      <td>14.414750</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>286.336781</td>\n      <td>238.386781</td>\n      <td>386.597556</td>\n      <td>130.5758</td>\n      <td>189.233112</td>\n      <td>3.353189</td>\n      <td>14.494013</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指数平滑\n",
    "def expPreprocessing(df, alpha=0.05):\n",
    "    edata = df.ewm(alpha=alpha, adjust=False).mean()\n",
    "    return edata\n",
    "\n",
    "alpha = 0.05\n",
    "data_exp = expPreprocessing(data, alpha)\n",
    "data_exp.head()\n",
    "\n",
    "# alpha = 0.05\n",
    "# data_exp = data.ewm(alpha=alpha, adjust=False).mean()\n",
    "# data_exp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化\n",
    "min_value = data_exp.min(axis=0)  \n",
    "max_value = data_exp.max(axis=0)\n",
    "\n",
    "data_std = (data_exp - min_value) / (max_value - min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集与验证集\n",
    "\n",
    "time_stamp = 50  # 时间点长度\n",
    "ratio = 0.8\n",
    "\n",
    "split = int(ratio*len(data))\n",
    "train_data = data_std[0:split + time_stamp]\n",
    "valid_data = data_std[split - time_stamp:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column = 0 # 标签所在的列id\n",
    "forecast_horizon = 5 # 预测的步数\n",
    "x_train, y_train = [], []\n",
    "scaled_data = train_data.values\n",
    "# 训练集\n",
    "for i in range(time_stamp, len(train_data) - forecast_horizon + 1):\n",
    "    x_train.append(scaled_data[i - time_stamp:i])\n",
    "    y_train.append(scaled_data[i:i + forecast_horizon, label_column])\n",
    "\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "# 验证集\n",
    "x_valid, y_valid = [], []\n",
    "for i in range(time_stamp, len(valid_data) - forecast_horizon + 1):\n",
    "    x_valid.append(scaled_data[i - time_stamp:i])\n",
    "    y_valid.append(scaled_data[i:i + forecast_horizon, label_column])\n",
    "\n",
    "x_valid, y_valid = np.array(x_valid), np.array(y_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网络定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "def ADNNet_model(x, hidden_1, hidden_2, dropout_rate=0.1, attention_dim=11, num_heads=4):\n",
    "    x_input = Input(shape=(x.shape[1], x.shape[2]))\n",
    "    # x_input1 = layers.Conv1D(filters=34, kernel_size=1, padding='same', activation='relu')(x_input)\n",
    "    # x_input1 = layers.MaxPool1D(pool_size=7, padding='valid')(x_input1)\n",
    "    \n",
    "    AQI, P = x_input[:,:,0], x_input[:,:,1:]\n",
    "    feature_time_lag = mlp(AQI, [hidden_1, hidden_2], dropout_rate)\n",
    "    feature_pol_con = mlp(P, [hidden_1, hidden_2], dropout_rate)\n",
    "    feature_seasonal = mlp(x_input, [hidden_1, hidden_2], dropout_rate)\n",
    "    \n",
    "    x_input1= layers.Dense(hidden_2)(x_input)\n",
    "    '''\n",
    "    ######################### 方法一 ######################### \n",
    "    x_features = layers.Add()([x_input1, feature_time_lag, feature_pol_con, feature_seasonal])\n",
    "    \n",
    "    attention_output = layers.MultiHeadAttention(\n",
    "        num_heads=num_heads, key_dim=attention_dim, dropout=0.0799\n",
    "    )(x_input1, x_features)\n",
    "    # Skip connection 1.\n",
    "    x2 = layers.Add()([attention_output, x_input1])\n",
    "    '''\n",
    "    '''\n",
    "    ######################### 方法二 ######################### \n",
    "    x_features = layers.Add()([x_input1, feature_time_lag, feature_pol_con, feature_seasonal])\n",
    "    attention_output = layers.MultiHeadAttention(\n",
    "        num_heads=num_heads, key_dim=attention_dim, dropout=0.0799\n",
    "    )(x_features, x_features)\n",
    "    # Skip connection 1.\n",
    "    x2 = layers.Add()([attention_output, x_features])\n",
    "    '''\n",
    "    ######################### 方法三 ######################### \n",
    "    attention_output = layers.MultiHeadAttention(\n",
    "        num_heads=num_heads, key_dim=attention_dim, dropout=0.0799\n",
    "    )(x_input1, x_input1)\n",
    "    # Skip connection 1.\n",
    "    x2 = layers.Add()([attention_output, feature_time_lag, feature_pol_con, feature_seasonal])\n",
    "    \n",
    "    \n",
    "    # Layer normalization 2.\n",
    "    x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "    # MLP.\n",
    "    x3 = mlp(x3, hidden_units=[hidden_2], dropout_rate=dropout_rate)\n",
    "\n",
    "    # Skip connection 2.\n",
    "    encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, attention_dim] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(dropout_rate)(representation)\n",
    "    # Classify outputs.\n",
    "    logits = layers.Dense(5)(representation)\n",
    "    logits = layers.Dropout(dropout_rate)(logits)\n",
    "    # Create the Keras model.\n",
    "    return Model(inputs=x_input, outputs=logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 贝叶斯参数优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self, \n",
    "                 x_train, \n",
    "                 y_train, \n",
    "                 x_valid, \n",
    "                 y_valid,  \n",
    "                 num_heads=4,\n",
    "                 epochs=50, \n",
    "                 batch_size=64,\n",
    "                 n_trials=100\n",
    "                ):\n",
    "        self.x_train, self.y_train, self.x_valid, self.y_valid = x_train, y_train, x_valid, y_valid\n",
    "        self.num_heads = num_heads\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.n_trials = n_trials\n",
    "        \n",
    "\n",
    "    def objective(self, trial):\n",
    "        lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
    "        hidden_1 = trial.suggest_int('hidden_1', 32, 256)\n",
    "        hidden_2 = trial.suggest_int('hidden_2', 32, 256)\n",
    "        dropout_rate = trial.suggest_uniform('dropout_rate', 0., 0.01)\n",
    "        attention_dim = trial.suggest_int('attention_dim', 8, 128)\n",
    "        \n",
    "        model = ADNNet_model(x=self.x_train, \n",
    "                                  hidden_1=hidden_1, \n",
    "                                  hidden_2=hidden_2, \n",
    "                                  dropout_rate=dropout_rate, \n",
    "                                  attention_dim=attention_dim, \n",
    "                                  num_heads=self.num_heads\n",
    "                                 )\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "        model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "        model.fit(self.x_train, self.y_train, epochs=self.epochs, batch_size=self.batch_size, verbose=0)\n",
    "\n",
    "        #score = model.evaluate(x_valid, y_valid, verbose=0)\n",
    "        y_pred = model.predict(self.x_valid)\n",
    "        score = mean_squared_error(self.y_valid, y_pred)\n",
    "\n",
    "        return score\n",
    "    \n",
    "    def optimizer_optuna(self):\n",
    "        algo = optuna.samplers.TPESampler()\n",
    "        study = optuna.create_study(sampler=algo, direction='minimize')\n",
    "        study.optimize(self.objective, n_trials=self.n_trials, show_progress_bar=True)\n",
    "        return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2024-01-30 10:14:35,724]\u001B[0m A new study created in memory with name: no-name-556fdaf6-3514-42f4-9514-ac4d1c794958\u001B[0m\n",
      "D:\\anaconda3\\lib\\site-packages\\optuna\\progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd0e96c7df6241dc9a5b0033b9140daa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2024-01-30 10:14:51,132]\u001B[0m Trial 0 finished with value: 0.008084374459970088 and parameters: {'lr': 0.0022544666868174884, 'hidden_1': 239, 'hidden_2': 175, 'dropout_rate': 0.009001480814138383, 'attention_dim': 31}. Best is trial 0 with value: 0.008084374459970088.\u001B[0m\n",
      "\u001B[32m[I 2024-01-30 10:15:10,505]\u001B[0m Trial 1 finished with value: 0.0045402224182778325 and parameters: {'lr': 0.003043909769740776, 'hidden_1': 125, 'hidden_2': 249, 'dropout_rate': 0.0055252819649870616, 'attention_dim': 48}. Best is trial 1 with value: 0.0045402224182778325.\u001B[0m\n",
      "\u001B[32m[I 2024-01-30 10:15:30,268]\u001B[0m Trial 2 finished with value: 0.002704850136783534 and parameters: {'lr': 0.00037361014766595344, 'hidden_1': 227, 'hidden_2': 155, 'dropout_rate': 0.00048369551964423717, 'attention_dim': 100}. Best is trial 2 with value: 0.002704850136783534.\u001B[0m\n",
      "\u001B[32m[I 2024-01-30 10:15:43,772]\u001B[0m Trial 3 finished with value: 0.0032983334382383532 and parameters: {'lr': 0.0004532588106085918, 'hidden_1': 185, 'hidden_2': 139, 'dropout_rate': 0.0015756014750357118, 'attention_dim': 23}. Best is trial 2 with value: 0.002704850136783534.\u001B[0m\n",
      "\u001B[32m[I 2024-01-30 10:15:56,591]\u001B[0m Trial 4 finished with value: 0.006558062967201579 and parameters: {'lr': 8.470294505024485e-05, 'hidden_1': 204, 'hidden_2': 62, 'dropout_rate': 0.009009215779766058, 'attention_dim': 74}. Best is trial 2 with value: 0.002704850136783534.\u001B[0m\n",
      "\u001B[32m[I 2024-01-30 10:16:13,878]\u001B[0m Trial 5 finished with value: 0.0041115719749676306 and parameters: {'lr': 0.0044902131404422, 'hidden_1': 46, 'hidden_2': 161, 'dropout_rate': 0.00042461432272900224, 'attention_dim': 81}. Best is trial 2 with value: 0.002704850136783534.\u001B[0m\n",
      "\u001B[32m[I 2024-01-30 10:16:26,225]\u001B[0m Trial 6 finished with value: 0.009603716133502445 and parameters: {'lr': 3.7028547406153784e-05, 'hidden_1': 155, 'hidden_2': 126, 'dropout_rate': 0.005612791428195674, 'attention_dim': 14}. Best is trial 2 with value: 0.002704850136783534.\u001B[0m\n",
      "\u001B[32m[I 2024-01-30 10:16:48,685]\u001B[0m Trial 7 finished with value: 0.007250292504505577 and parameters: {'lr': 1.968801140660882e-05, 'hidden_1': 214, 'hidden_2': 177, 'dropout_rate': 0.0055699425932544825, 'attention_dim': 99}. Best is trial 2 with value: 0.002704850136783534.\u001B[0m\n",
      "\u001B[32m[I 2024-01-30 10:17:05,199]\u001B[0m Trial 8 finished with value: 0.01100017892032095 and parameters: {'lr': 0.00629591566252411, 'hidden_1': 148, 'hidden_2': 192, 'dropout_rate': 0.006807034530719826, 'attention_dim': 35}. Best is trial 2 with value: 0.002704850136783534.\u001B[0m\n",
      "\u001B[32m[I 2024-01-30 10:17:23,490]\u001B[0m Trial 9 finished with value: 0.007367147635916563 and parameters: {'lr': 3.2285122843904184e-05, 'hidden_1': 118, 'hidden_2': 123, 'dropout_rate': 0.009354180957280219, 'attention_dim': 79}. Best is trial 2 with value: 0.002704850136783534.\u001B[0m\n",
      "\n",
      "{'lr': 0.00037361014766595344, 'hidden_1': 227, 'hidden_2': 155, 'dropout_rate': 0.00048369551964423717, 'attention_dim': 100}\n",
      "0.002704850136783534\n"
     ]
    }
   ],
   "source": [
    "# 超参数\n",
    "epochs = 5\n",
    "batch_size = 64\n",
    "num_heads = 4\n",
    "n_trials = 10\n",
    "\n",
    "T = Trainer(x_train, y_train, x_valid, y_valid, num_heads=num_heads, epochs=epochs, batch_size=batch_size, n_trials=n_trials)\n",
    "study = T.optimizer_optuna()\n",
    "print(study.best_params)\n",
    "print(study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "41/41 [==============================] - 5s 100ms/step - loss: 0.5655\n",
      "Epoch 2/50\n",
      " 1/41 [..............................] - ETA: 3s - loss: 0.0234"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 4s 100ms/step - loss: 0.0101\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 4s 102ms/step - loss: 0.0055\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 4s 101ms/step - loss: 0.0046\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 4s 102ms/step - loss: 0.0045\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 4s 105ms/step - loss: 0.0044\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 4s 103ms/step - loss: 0.0041\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 4s 105ms/step - loss: 0.0043\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 4s 103ms/step - loss: 0.0040\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 4s 103ms/step - loss: 0.0039\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 4s 104ms/step - loss: 0.0041\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 4s 102ms/step - loss: 0.0045\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 4s 104ms/step - loss: 0.0041\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 4s 102ms/step - loss: 0.0042\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 4s 104ms/step - loss: 0.0044\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 4s 104ms/step - loss: 0.0045\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 4s 101ms/step - loss: 0.0046\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 4s 103ms/step - loss: 0.0039\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 4s 102ms/step - loss: 0.0036\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 4s 105ms/step - loss: 0.0044\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 4s 104ms/step - loss: 0.0044\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - 4s 100ms/step - loss: 0.0045\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 4s 104ms/step - loss: 0.0043\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 4s 104ms/step - loss: 0.0046\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 4s 103ms/step - loss: 0.0040\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 4s 99ms/step - loss: 0.0046\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 4s 101ms/step - loss: 0.0045\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - 4s 102ms/step - loss: 0.0041\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - 4s 101ms/step - loss: 0.0038\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 4s 105ms/step - loss: 0.0043\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 4s 102ms/step - loss: 0.0044\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 4s 103ms/step - loss: 0.0043\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 4s 102ms/step - loss: 0.0038\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 4s 101ms/step - loss: 0.0047\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 4s 102ms/step - loss: 0.0040\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 4s 99ms/step - loss: 0.0042\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 4s 103ms/step - loss: 0.0059\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 4s 103ms/step - loss: 0.0052\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 4s 101ms/step - loss: 0.0058\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 4s 100ms/step - loss: 0.0045\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 4s 102ms/step - loss: 0.0035\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 4s 101ms/step - loss: 0.0039\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 4s 100ms/step - loss: 0.0035\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - 4s 100ms/step - loss: 0.0040\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - 4s 100ms/step - loss: 0.0032\n",
      "Epoch 46/50\n",
      "41/41 [==============================] - 4s 99ms/step - loss: 0.0045\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - 4s 98ms/step - loss: 0.0036\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - 4s 96ms/step - loss: 0.0036\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - 4s 98ms/step - loss: 0.0041\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - 4s 102ms/step - loss: 0.0039\n"
     ]
    }
   ],
   "source": [
    "# 根据最优超参，训练和预测\n",
    "params = study.best_params\n",
    "lr = params['lr']\n",
    "hidden_1 = params['hidden_1']\n",
    "hidden_2 = params['hidden_2']\n",
    "dropout_rate = params['dropout_rate']\n",
    "attention_dim = params['attention_dim']\n",
    "\n",
    "checkpoint_path_best = \"data/best.hdf5\"\n",
    "modelcheckpoint_best = keras.callbacks.ModelCheckpoint(checkpoint_path_best,\n",
    "                                                       monitor='loss',\n",
    "                                                       save_best_only=True, \n",
    "                                                       mode='min', \n",
    "                                                       verbose=0)\n",
    "model = transformer_model(x=x_train, \n",
    "                          hidden_1=hidden_1, \n",
    "                          hidden_2=hidden_2, \n",
    "                          dropout_rate=dropout_rate, \n",
    "                          attention_dim=attention_dim,\n",
    "                         )\n",
    "#print(model.summary())\n",
    "model.compile(loss='mean_squared_error', optimizer=keras.optimizers.Adam(learning_rate=lr))\n",
    "model.fit(x_train, y_train, epochs=50, batch_size=batch_size, verbose=1, callbacks=[modelcheckpoint_best])\n",
    "\n",
    "model.load_weights(checkpoint_path_best)\n",
    "closing_price = model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.41351092, 0.34056708, 0.49436292, 0.4236973 , 0.36763814],\n       [0.4044084 , 0.32993904, 0.4990879 , 0.41560453, 0.3611808 ],\n       [0.4152282 , 0.33575004, 0.48480025, 0.40048563, 0.3471617 ],\n       ...,\n       [0.11736793, 0.05283482, 0.20053434, 0.10354332, 0.10722256],\n       [0.13131185, 0.0553672 , 0.20040154, 0.11721755, 0.10457492],\n       [0.13084204, 0.08349486, 0.21330151, 0.14712508, 0.12259388]],\n      dtype=float32)"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closing_price"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0           1           2           3           4\n",
      "0    167.431957  166.060360  165.857342  169.814475  165.873751\n",
      "1    166.060360  165.857342  169.814475  165.873751  160.430063\n",
      "2    165.857342  169.814475  165.873751  160.430063  159.258560\n",
      "3    169.814475  165.873751  160.430063  159.258560  155.195632\n",
      "4    165.873751  160.430063  159.258560  155.195632  152.735850\n",
      "..          ...         ...         ...         ...         ...\n",
      "646   79.746129   78.708823   79.773382   85.684712   90.000477\n",
      "647   78.708823   79.773382   85.684712   90.000477   92.700453\n",
      "648   79.773382   85.684712   90.000477   92.700453   95.865430\n",
      "649   85.684712   90.000477   92.700453   95.865430   96.222159\n",
      "650   90.000477   92.700453   95.865430   96.222159   93.211051\n",
      "\n",
      "[651 rows x 5 columns]\n",
      "              0           1           2           3           4\n",
      "0    162.280334  143.907898  182.644623  164.845993  150.726318\n",
      "1    159.987671  141.231003  183.834717  162.807663  149.099899\n",
      "2    162.712875  142.694626  180.236069  158.999649  145.568893\n",
      "3    163.287231  143.797607  177.226181  158.322830  145.531509\n",
      "4    165.567291  144.472382  178.710770  160.178146  147.751221\n",
      "..          ...         ...         ...         ...         ...\n",
      "646   88.358093   72.581276  110.095291   89.095428   83.599266\n",
      "647   88.071594   70.181236  107.935638   87.844757   83.289116\n",
      "648   87.690475   71.436455  108.637695   84.208458   85.135147\n",
      "649   91.202545   72.074287  108.604248   87.652603   84.468292\n",
      "650   91.084213   79.158829  111.853378   95.185440   89.006744\n",
      "\n",
      "[651 rows x 5 columns]\n",
      "{'RMSE': [7.716913203197654, 12.702063451826746, 26.876615007063098, 8.87285475018355, 8.116547887418477], 'MAE': [6.875604593382542, 10.989504256493193, 26.083607132109385, 7.481234403049943, 6.030552965511402], 'R2Score': [0.9034061196570689, 0.7363716606013513, -0.1889331963560641, 0.869465313266804, 0.8898512972711612], 'MAPE': [6.749811916557956, 9.732860628425147, 25.483263086399194, 7.2785571550237185, 5.366245064509933]}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 假设 max_value, min_value, alpha, label_column 已正确定义\n",
    "# max_value = {...}\n",
    "# min_value = {...}\n",
    "# alpha = ...\n",
    "# label_column = ...\n",
    "y_valid_list = [y_valid]\n",
    "# 反归一化\n",
    "def unnormalize(data, max_value, min_value, label_column):\n",
    "    return (data * (max_value[label_column] - min_value[label_column])) + min_value[label_column]\n",
    "\n",
    "y_valid_original = unnormalize(pd.DataFrame(y_valid_list[0]), max_value, min_value, label_column)\n",
    "predictions_original = unnormalize(pd.DataFrame(closing_price), max_value, min_value, label_column)\n",
    "\n",
    "# 反平滑\n",
    "# def exp_reversed(df, alpha):\n",
    "#     reversed_df = pd.DataFrame()\n",
    "#     for column in df.columns:\n",
    "#         df_col = df[column]\n",
    "#         row_0 = df_col.iloc[0]\n",
    "#         df_t_1 = pd.Series([row_0]).append(df_col[:-1]).reset_index(drop=True)\n",
    "#         result = (df_col - (1 - alpha) * df_t_1) / alpha\n",
    "#         result.iloc[0] = df_col.iloc[0]\n",
    "#         reversed_df = pd.concat([reversed_df, result], axis=1)\n",
    "#     return reversed_df\n",
    "original_y_valid = y_valid_original\n",
    "original_predictions = predictions_original\n",
    "# original_y_valid = exp_reversed(y_valid_original, alpha)\n",
    "# original_predictions = exp_reversed(predictions_original, alpha)\n",
    "print(original_y_valid)\n",
    "print(original_predictions)\n",
    "# 评估每一步的预测\n",
    "metrics = {'RMSE': [], 'MAE': [], 'R2Score': [], 'MAPE': []}\n",
    "for step in range(5):\n",
    "    # 计算每个指标\n",
    "    rmse = np.sqrt(mean_squared_error(original_y_valid.iloc[:, step], original_predictions.iloc[:, step]))\n",
    "    mae = mean_absolute_error(original_y_valid.iloc[:, step], original_predictions.iloc[:, step])\n",
    "    r2 = r2_score(original_y_valid.iloc[:, step], original_predictions.iloc[:, step])\n",
    "    mape = np.mean(np.abs((original_y_valid.iloc[:, step] - original_predictions.iloc[:, step]) / original_y_valid.iloc[:, step])) * 100\n",
    "\n",
    "    # 存储指标\n",
    "    metrics['RMSE'].append(rmse)\n",
    "    metrics['MAE'].append(mae)\n",
    "    metrics['R2Score'].append(r2)\n",
    "    metrics['MAPE'].append(mape)\n",
    "\n",
    "# 输出指标\n",
    "print(metrics)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RMSE': [0.0306383483519987, 0.050430801259047205, 0.10670781917967968, 0.035227763396814125, 0.03222500289513167], 'MAE': [0.02729811385178442, 0.043631452462003006, 0.10355935255224184, 0.029702633993402384, 0.02394301014189962], 'R2Score': [0.90340607855537, 0.7363717228480356, -0.18893337191901605, 0.8694652790779555, 0.8898513135433184], 'MAPE': [20.10864159798638, 24.258492814531117, 75.93891538016484, 22.993170586387464, 14.14609752123918]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "y_valid_list = [y_valid]\n",
    "# # 假设您的模型已经产生了5步预测\n",
    "# predictions = model.predict(y_valid_list)  # 这应该是一个形状为 (n_samples, 5) 的数组\n",
    "\n",
    "# 初始化指标\n",
    "metrics = {'RMSE': [], 'MAE': [], 'R2Score': [], 'MAPE': []}\n",
    "y_valid = pd.DataFrame(y_valid_list[0])\n",
    "predictions =  pd.DataFrame(closing_price)\n",
    "# 对于每一步预测\n",
    "for step in range(5):\n",
    "    # 计算每个指标\n",
    "    rmse = np.sqrt(mean_squared_error(y_valid.iloc[:, step], predictions.iloc[:, step]))\n",
    "    mae = mean_absolute_error(y_valid.iloc[:, step], predictions.iloc[:, step])\n",
    "    r2 = r2_score(y_valid.iloc[:, step], predictions.iloc[:, step])\n",
    "    mape = np.mean(np.abs((y_valid.iloc[:, step] - predictions.iloc[:, step]) / y_valid.iloc[:, step])) * 100\n",
    "\n",
    "    # 存储指标\n",
    "    metrics['RMSE'].append(rmse)\n",
    "    metrics['MAE'].append(mae)\n",
    "    metrics['R2Score'].append(r2)\n",
    "    metrics['MAPE'].append(mape)\n",
    "\n",
    "# 输出指标\n",
    "print(metrics)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # closing_price = scaler.inverse_transform(closing_price)\n",
    "# # y_valid = scaler.inverse_transform([y_valid])\n",
    "# y_valid_list = [y_valid]\n",
    "#\n",
    "# mse_2 = mean_squared_error(y_valid_list[0], closing_price.reshape(1,-1)[0])\n",
    "# print(\"RMSE \", np.sqrt(mse_2))\n",
    "# mae = mean_absolute_error(y_valid_list[0], closing_price.reshape(1,-1)[0])\n",
    "# print(\"MAE \", mae)\n",
    "# r2 = r2_score(y_valid_list[0], closing_price.reshape(1,-1)[0])\n",
    "# print(\"R2SCORE \", r2)\n",
    "# mape = mean_absolute_percentage_error(y_valid_list[0], closing_price.reshape(1,-1)[0])\n",
    "# print(\"MAPE \", mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "#\n",
    "# # 反归一化\n",
    "# closing_price_original = (closing_price.reshape(-1, 1) * (max_value[label_column] - min_value[label_column])) + min_value[label_column]\n",
    "# y_valid_original = (y_valid.reshape(-1, 1) * (max_value[label_column] - min_value[label_column])) + min_value[label_column]\n",
    "# # 创建图表\n",
    "# plt.figure(figsize=(16, 8))\n",
    "# dict_data = {\n",
    "#     'Predictions': closing_price_original.flatten(),\n",
    "#     'Close': y_valid_original.flatten()\n",
    "# }\n",
    "# data_pd = pd.DataFrame(dict_data)\n",
    "# plt.plot(data_pd[['Close', 'Predictions']])\n",
    "# plt.legend(['Close', 'Predictions'], loc='upper right')\n",
    "# plt.show()\n",
    "# # 保存预测值\n",
    "# pd.DataFrame(closing_price_original).to_csv('data/ADNNet_pred_BJ.csv', index=False)\n",
    "# pd.DataFrame(y_valid_original).to_csv('data/Real_BJ.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # valid.iloc[time_stamp:,0].values == y_valid\n",
    "#\n",
    "# train_labels = list(data.iloc[:split,0])   # data.iloc[split:,0]\n",
    "# test_labels = list(data.iloc[:,0])\n",
    "#\n",
    "# prediction_values = closing_price.reshape(1,-1)[0]\n",
    "# prediction_exp = prediction_values * (max_value[0] - min_value[0]) + min_value[0]\n",
    "# prediction_list = list(prediction_exp)\n",
    "# all_labels = train_labels + prediction_list\n",
    "#\n",
    "# labels_dict = {'prediction': all_labels, 'test': test_labels}\n",
    "# df_labels = pd.DataFrame(labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def exp_reversed(df, alpha):\n",
    "#     row_0 = df.iloc[0]\n",
    "#     df_t_1 = df.iloc[:0].append(row_0, ignore_index=True).append(df.iloc[:-1], ignore_index=True)\n",
    "#     results = (df - (1-alpha)*df_t_1)/alpha\n",
    "#     results.iloc[0] = df.iloc[0]\n",
    "#     return results\n",
    "#\n",
    "# original_labels = exp_reversed(df_labels, alpha)\n",
    "# original_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
