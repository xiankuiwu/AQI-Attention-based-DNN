{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras as keras\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Activation, Input, Dense, Dropout, Flatten, Conv1D, MaxPooling1D, Reshape, Concatenate, concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   AQI  PM2.5  PM10  NO2  SO2   CO  O3_8h\n0  310    260   420  139  201  3.5     13\n1  225    175   271  111  143  3.2     31\n2  275    225   360  128  197  3.9     12\n3  126     96   183   70  101  2.3     26\n4  116     88   159   70  114  1.6     16",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AQI</th>\n      <th>PM2.5</th>\n      <th>PM10</th>\n      <th>NO2</th>\n      <th>SO2</th>\n      <th>CO</th>\n      <th>O3_8h</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>310</td>\n      <td>260</td>\n      <td>420</td>\n      <td>139</td>\n      <td>201</td>\n      <td>3.5</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>225</td>\n      <td>175</td>\n      <td>271</td>\n      <td>111</td>\n      <td>143</td>\n      <td>3.2</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>275</td>\n      <td>225</td>\n      <td>360</td>\n      <td>128</td>\n      <td>197</td>\n      <td>3.9</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>126</td>\n      <td>96</td>\n      <td>183</td>\n      <td>70</td>\n      <td>101</td>\n      <td>2.3</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>116</td>\n      <td>88</td>\n      <td>159</td>\n      <td>70</td>\n      <td>114</td>\n      <td>1.6</td>\n      <td>16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取数据\n",
    "data_ini = pd.read_excel('data/TJ POLTS.xlsx')\n",
    "\n",
    "data = data_ini.iloc[:,[1,3,4,5,6,7,8]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "          AQI       PM2.5        PM10       NO2         SO2        CO  \\\n0  310.000000  260.000000  420.000000  139.0000  201.000000  3.500000   \n1  305.750000  255.750000  412.550000  137.6000  198.100000  3.485000   \n2  304.212500  254.212500  409.922500  137.1200  198.045000  3.505750   \n3  295.301875  246.301875  398.576375  133.7640  193.192750  3.445462   \n4  286.336781  238.386781  386.597556  130.5758  189.233112  3.353189   \n\n       O3_8h  \n0  13.000000  \n1  13.900000  \n2  13.805000  \n3  14.414750  \n4  14.494013  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AQI</th>\n      <th>PM2.5</th>\n      <th>PM10</th>\n      <th>NO2</th>\n      <th>SO2</th>\n      <th>CO</th>\n      <th>O3_8h</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>310.000000</td>\n      <td>260.000000</td>\n      <td>420.000000</td>\n      <td>139.0000</td>\n      <td>201.000000</td>\n      <td>3.500000</td>\n      <td>13.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>305.750000</td>\n      <td>255.750000</td>\n      <td>412.550000</td>\n      <td>137.6000</td>\n      <td>198.100000</td>\n      <td>3.485000</td>\n      <td>13.900000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>304.212500</td>\n      <td>254.212500</td>\n      <td>409.922500</td>\n      <td>137.1200</td>\n      <td>198.045000</td>\n      <td>3.505750</td>\n      <td>13.805000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>295.301875</td>\n      <td>246.301875</td>\n      <td>398.576375</td>\n      <td>133.7640</td>\n      <td>193.192750</td>\n      <td>3.445462</td>\n      <td>14.414750</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>286.336781</td>\n      <td>238.386781</td>\n      <td>386.597556</td>\n      <td>130.5758</td>\n      <td>189.233112</td>\n      <td>3.353189</td>\n      <td>14.494013</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指数平滑\n",
    "def expPreprocessing(df, alpha=0.05):\n",
    "    edata = df.ewm(alpha=alpha, adjust=False).mean()\n",
    "    return edata\n",
    "\n",
    "alpha = 0.05\n",
    "data_exp = expPreprocessing(data, alpha)\n",
    "data_exp.head()\n",
    "\n",
    "# alpha = 0.05\n",
    "# data_exp = data.ewm(alpha=alpha, adjust=False).mean()\n",
    "# data_exp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化\n",
    "min_value = data_exp.min(axis=0)  \n",
    "max_value = data_exp.max(axis=0)\n",
    "\n",
    "data_std = (data_exp - min_value) / (max_value - min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集与验证集\n",
    "\n",
    "time_stamp = 50  # 时间点长度\n",
    "ratio = 0.8\n",
    "\n",
    "split = int(ratio*len(data))\n",
    "train_data = data_std[0:split + time_stamp]\n",
    "valid_data = data_std[split - time_stamp:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column = 0 # 标签所在的列id\n",
    "forecast_horizon = 5 # 预测的步数\n",
    "x_train, y_train = [], []\n",
    "scaled_data = train_data.values\n",
    "# 训练集\n",
    "for i in range(time_stamp, len(train_data) - forecast_horizon + 1):\n",
    "    x_train.append(scaled_data[i - time_stamp:i])\n",
    "    y_train.append(scaled_data[i:i + forecast_horizon, label_column])\n",
    "\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "# 验证集\n",
    "x_valid, y_valid = [], []\n",
    "for i in range(time_stamp, len(valid_data) - forecast_horizon + 1):\n",
    "    x_valid.append(scaled_data[i - time_stamp:i])\n",
    "    y_valid.append(scaled_data[i:i + forecast_horizon, label_column])\n",
    "\n",
    "x_valid, y_valid = np.array(x_valid), np.array(y_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 贝叶斯参数优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, MultiHeadAttention, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import optuna\n",
    "def InformerBlock(input_layer, head_size, num_heads, ff_dim, dropout_rate):\n",
    "    # 概率稀疏自注意力层 (这里简化为普通的多头注意力)\n",
    "    attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=head_size, dropout=dropout_rate)(input_layer, input_layer)\n",
    "    attention_output = Dropout(dropout_rate)(attention_output)\n",
    "    attention_output = LayerNormalization(epsilon=1e-6)(attention_output + input_layer)\n",
    "\n",
    "    # 前馈网络\n",
    "    ffn_output = Dense(ff_dim, activation=\"relu\")(attention_output)\n",
    "    ffn_output = Dense(input_layer.shape[-1])(ffn_output)\n",
    "    ffn_output = Dropout(dropout_rate)(ffn_output)\n",
    "    ffn_output = LayerNormalization(epsilon=1e-6)(ffn_output + attention_output)\n",
    "\n",
    "    return ffn_output\n",
    "\n",
    "def informer_model(input_shape, head_size, num_heads, ff_dim, num_blocks, dropout_rate):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = inputs\n",
    "\n",
    "    # Informer块\n",
    "    for _ in range(num_blocks):\n",
    "        x = InformerBlock(x, head_size, num_heads, ff_dim, dropout_rate)\n",
    "\n",
    "    # 输出层\n",
    "    x = Flatten()(x)\n",
    "    outputs = Dense(5)(x)  # 假设目标是预测一个数值\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, x_train, y_train, x_valid, y_valid, epochs=50, batch_size=64, n_trials=100):\n",
    "        self.x_train, self.y_train, self.x_valid, self.y_valid = x_train, y_train, x_valid, y_valid\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.n_trials = n_trials\n",
    "    def objective(self, trial):\n",
    "        lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
    "        head_size = trial.suggest_categorical('head_size', [32, 64, 128])\n",
    "        num_heads = trial.suggest_int('num_heads', 1, 4)\n",
    "        ff_dim = trial.suggest_int('ff_dim', 32, 128)\n",
    "        num_blocks = trial.suggest_int('num_blocks', 1, 4)\n",
    "        dropout_rate = trial.suggest_uniform('dropout_rate', 0., 0.5)\n",
    "\n",
    "        model = informer_model(self.x_train.shape[1:], head_size, num_heads, ff_dim, num_blocks, dropout_rate)\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "        model.fit(self.x_train, self.y_train, epochs=self.epochs, batch_size=self.batch_size, verbose=0)\n",
    "\n",
    "        y_pred = model.predict(self.x_valid)\n",
    "        score = mean_squared_error(self.y_valid, y_pred)\n",
    "\n",
    "        return score\n",
    "\n",
    "    def optimizer_optuna(self):\n",
    "        sampler = optuna.samplers.TPESampler()\n",
    "        study = optuna.create_study(sampler=sampler, direction='minimize')\n",
    "        study.optimize(self.objective, n_trials=self.n_trials, show_progress_bar=True)\n",
    "        return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2024-01-30 11:06:05,529]\u001B[0m A new study created in memory with name: no-name-15c2d765-e934-40e7-bcb2-6e3b5c3bc098\u001B[0m\n",
      "D:\\anaconda3\\lib\\site-packages\\optuna\\progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7347526df91b4aff86c7a5fe5f6ddb95"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2024-01-30 11:06:08,202]\u001B[0m Trial 0 finished with value: 0.4472782776271231 and parameters: {'lr': 3.3162357056976886e-05, 'head_size': 32, 'num_heads': 2, 'ff_dim': 45, 'num_blocks': 1, 'dropout_rate': 0.11355969466440374}. Best is trial 0 with value: 0.4472782776271231.\u001B[0m\n",
      "\u001B[32m[I 2024-01-30 11:06:20,967]\u001B[0m Trial 1 finished with value: 0.00905340039938605 and parameters: {'lr': 0.00030984936682758166, 'head_size': 128, 'num_heads': 2, 'ff_dim': 73, 'num_blocks': 2, 'dropout_rate': 0.1880432425151407}. Best is trial 1 with value: 0.00905340039938605.\u001B[0m\n",
      "\u001B[32m[I 2024-01-30 11:06:26,350]\u001B[0m Trial 2 finished with value: 0.005734301904039597 and parameters: {'lr': 0.005446104238540606, 'head_size': 32, 'num_heads': 2, 'ff_dim': 112, 'num_blocks': 2, 'dropout_rate': 0.09224786261827478}. Best is trial 2 with value: 0.005734301904039597.\u001B[0m\n",
      "\u001B[32m[I 2024-01-30 11:06:49,858]\u001B[0m Trial 3 finished with value: 0.00523601504368883 and parameters: {'lr': 0.0003265072291503644, 'head_size': 64, 'num_heads': 3, 'ff_dim': 83, 'num_blocks': 4, 'dropout_rate': 0.03396885869057131}. Best is trial 3 with value: 0.00523601504368883.\u001B[0m\n",
      "\u001B[32m[I 2024-01-30 11:06:54,336]\u001B[0m Trial 4 finished with value: 0.013024338454672662 and parameters: {'lr': 0.00021258532208575916, 'head_size': 64, 'num_heads': 1, 'ff_dim': 67, 'num_blocks': 2, 'dropout_rate': 0.16155818395389915}. Best is trial 3 with value: 0.00523601504368883.\u001B[0m\n",
      "\n",
      "{'lr': 0.0003265072291503644, 'head_size': 64, 'num_heads': 3, 'ff_dim': 83, 'num_blocks': 4, 'dropout_rate': 0.03396885869057131}\n",
      "0.00523601504368883\n"
     ]
    }
   ],
   "source": [
    "# 超参数\n",
    "epochs = 5\n",
    "batch_size = 64\n",
    "num_heads = 4\n",
    "n_trials = 5\n",
    "T = Trainer(x_train, y_train, x_valid, y_valid, epochs=epochs, batch_size=batch_size, n_trials=n_trials)\n",
    "study = T.optimizer_optuna()\n",
    "print(study.best_params)\n",
    "print(study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "41/41 [==============================] - 6s 109ms/step - loss: 0.1981\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 4s 104ms/step - loss: 0.0190\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 4s 105ms/step - loss: 0.0146\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 4s 104ms/step - loss: 0.0128\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 4s 104ms/step - loss: 0.0110\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 4s 105ms/step - loss: 0.0096\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 4s 104ms/step - loss: 0.0088\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 4s 104ms/step - loss: 0.0081\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 4s 105ms/step - loss: 0.0073\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 4s 104ms/step - loss: 0.0068\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 4s 105ms/step - loss: 0.0063\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 4s 104ms/step - loss: 0.0059\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 4s 104ms/step - loss: 0.0054\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 4s 104ms/step - loss: 0.0052\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 4s 104ms/step - loss: 0.0049\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 4s 105ms/step - loss: 0.0047\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 4s 105ms/step - loss: 0.0046\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 4s 105ms/step - loss: 0.0045\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 4s 105ms/step - loss: 0.0043\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 4s 107ms/step - loss: 0.0041\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 4s 106ms/step - loss: 0.0041\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - 4s 106ms/step - loss: 0.0040\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 4s 106ms/step - loss: 0.0039\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 4s 106ms/step - loss: 0.0038\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 4s 107ms/step - loss: 0.0037\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 4s 107ms/step - loss: 0.0036\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 4s 107ms/step - loss: 0.0037\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - 4s 106ms/step - loss: 0.0036\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - 5s 110ms/step - loss: 0.0035\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 4s 108ms/step - loss: 0.0033\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 4s 106ms/step - loss: 0.0032\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 4s 105ms/step - loss: 0.0032\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 4s 105ms/step - loss: 0.0032\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 4s 105ms/step - loss: 0.0031\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 4s 106ms/step - loss: 0.0030\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 4s 106ms/step - loss: 0.0030\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 4s 108ms/step - loss: 0.0030\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 4s 109ms/step - loss: 0.0032\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 4s 108ms/step - loss: 0.0031\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 4s 109ms/step - loss: 0.0029\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 4s 105ms/step - loss: 0.0027\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 4s 106ms/step - loss: 0.0027\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 4s 105ms/step - loss: 0.0026\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - 4s 105ms/step - loss: 0.0026\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - 4s 106ms/step - loss: 0.0025\n",
      "Epoch 46/50\n",
      "41/41 [==============================] - 4s 106ms/step - loss: 0.0025\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - 4s 106ms/step - loss: 0.0024\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - 4s 106ms/step - loss: 0.0023\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - 4s 106ms/step - loss: 0.0024\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - 4s 106ms/step - loss: 0.0026\n"
     ]
    }
   ],
   "source": [
    "# 根据最优超参，训练和预测\n",
    "params = study.best_params\n",
    "lr = params['lr']\n",
    "head_size = params['head_size']\n",
    "num_heads = params['num_heads']\n",
    "ff_dim = params['ff_dim']\n",
    "num_blocks = params['num_blocks']\n",
    "dropout_rate = params['dropout_rate']\n",
    "checkpoint_path_best = \"data/best.hdf5\"\n",
    "modelcheckpoint_best = keras.callbacks.ModelCheckpoint(checkpoint_path_best,\n",
    "                                                       monitor='loss',\n",
    "                                                       save_best_only=True,\n",
    "                                                       mode='min',\n",
    "                                                       verbose=0)\n",
    "#LSTM\n",
    "\n",
    "model = informer_model(x_train.shape[1:], head_size, num_heads, ff_dim, num_blocks, dropout_rate)\n",
    "\n",
    "#print(model.summary())\n",
    "model.compile(loss='mean_squared_error', optimizer=keras.optimizers.Adam(learning_rate=lr))\n",
    "model.fit(x_train, y_train, epochs=50, batch_size=batch_size, verbose=1, callbacks=[modelcheckpoint_best])\n",
    "\n",
    "model.load_weights(checkpoint_path_best)\n",
    "closing_price = model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0           1           2           3           4\n",
      "0    167.431957  166.060360  165.857342  169.814475  165.873751\n",
      "1    166.060360  165.857342  169.814475  165.873751  160.430063\n",
      "2    165.857342  169.814475  165.873751  160.430063  159.258560\n",
      "3    169.814475  165.873751  160.430063  159.258560  155.195632\n",
      "4    165.873751  160.430063  159.258560  155.195632  152.735850\n",
      "..          ...         ...         ...         ...         ...\n",
      "646   79.746129   78.708823   79.773382   85.684712   90.000477\n",
      "647   78.708823   79.773382   85.684712   90.000477   92.700453\n",
      "648   79.773382   85.684712   90.000477   92.700453   95.865430\n",
      "649   85.684712   90.000477   92.700453   95.865430   96.222159\n",
      "650   90.000477   92.700453   95.865430   96.222159   93.211051\n",
      "\n",
      "[651 rows x 5 columns]\n",
      "              0           1           2           3           4\n",
      "0    155.696838  151.284653  150.699341  154.655518  149.746964\n",
      "1    155.573257  151.235214  149.736389  153.486847  148.611938\n",
      "2    154.557800  150.877197  149.567612  152.727722  147.618286\n",
      "3    154.311981  150.164627  148.376831  153.046097  147.803391\n",
      "4    154.107178  149.928192  146.707047  153.117416  147.599548\n",
      "..          ...         ...         ...         ...         ...\n",
      "646   75.888359   79.111183   76.555374   81.018616   76.654091\n",
      "647   76.572517   79.931595   76.368774   81.582375   77.303482\n",
      "648   77.004303   80.375748   76.891495   81.086128   78.107285\n",
      "649   78.286079   80.556198   77.198746   81.081375   78.859184\n",
      "650   79.204330   80.871544   77.382889   81.319412   79.566284\n",
      "\n",
      "[651 rows x 5 columns]\n",
      "{'RMSE': [11.148769510539012, 11.840508230309402, 11.943074658619045, 11.651111655950801, 12.850929340376094], 'MAE': [8.737405869084274, 9.588325295743934, 9.663086037924872, 9.417279283442749, 10.233311577453817], 'R2Score': [0.7983880567217702, 0.7709215550744465, 0.7652310773871688, 0.7749215501125363, 0.7238749882719686], 'MAPE': [7.774830333070739, 8.615295580445839, 8.658186034191658, 8.514267077940222, 9.12699725366236]}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 假设 max_value, min_value, alpha, label_column 已正确定义\n",
    "# max_value = {...}\n",
    "# min_value = {...}\n",
    "# alpha = ...\n",
    "# label_column = ...\n",
    "y_valid_list = [y_valid]\n",
    "# 反归一化\n",
    "def unnormalize(data, max_value, min_value, label_column):\n",
    "    return (data * (max_value[label_column] - min_value[label_column])) + min_value[label_column]\n",
    "\n",
    "y_valid_original = unnormalize(pd.DataFrame(y_valid_list[0]), max_value, min_value, label_column)\n",
    "predictions_original = unnormalize(pd.DataFrame(closing_price), max_value, min_value, label_column)\n",
    "\n",
    "# 反平滑\n",
    "# def exp_reversed(df, alpha):\n",
    "#     reversed_df = pd.DataFrame()\n",
    "#     for column in df.columns:\n",
    "#         df_col = df[column]\n",
    "#         row_0 = df_col.iloc[0]\n",
    "#         df_t_1 = pd.Series([row_0]).append(df_col[:-1]).reset_index(drop=True)\n",
    "#         result = (df_col - (1 - alpha) * df_t_1) / alpha\n",
    "#         result.iloc[0] = df_col.iloc[0]\n",
    "#         reversed_df = pd.concat([reversed_df, result], axis=1)\n",
    "#     return reversed_df\n",
    "original_y_valid = y_valid_original\n",
    "original_predictions = predictions_original\n",
    "# original_y_valid = exp_reversed(y_valid_original, alpha)\n",
    "# original_predictions = exp_reversed(predictions_original, alpha)\n",
    "print(original_y_valid)\n",
    "print(original_predictions)\n",
    "# 评估每一步的预测\n",
    "metrics = {'RMSE': [], 'MAE': [], 'R2Score': [], 'MAPE': []}\n",
    "for step in range(5):\n",
    "    # 计算每个指标\n",
    "    rmse = np.sqrt(mean_squared_error(original_y_valid.iloc[:, step], original_predictions.iloc[:, step]))\n",
    "    mae = mean_absolute_error(original_y_valid.iloc[:, step], original_predictions.iloc[:, step])\n",
    "    r2 = r2_score(original_y_valid.iloc[:, step], original_predictions.iloc[:, step])\n",
    "    mape = np.mean(np.abs((original_y_valid.iloc[:, step] - original_predictions.iloc[:, step]) / original_y_valid.iloc[:, step])) * 100\n",
    "\n",
    "    # 存储指标\n",
    "    metrics['RMSE'].append(rmse)\n",
    "    metrics['MAE'].append(mae)\n",
    "    metrics['R2Score'].append(r2)\n",
    "    metrics['MAPE'].append(mape)\n",
    "\n",
    "# 输出指标\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RMSE': [0.044263784142620236, 0.04701018682697216, 0.047417402918999436, 0.04625822775190598, 0.05102184528293646], 'MAE': [0.034689985121327135, 0.03806838072763376, 0.038365200453581445, 0.037389277650160924, 0.04062915888912315], 'R2Score': [0.7983880933321863, 0.7709215642093721, 0.7652311047025887, 0.774921566708515, 0.7238750086008228], 'MAPE': [21.244430468340543, 24.563982636611993, 23.671209132924922, 25.798067915096574, 26.225328149197896]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "y_valid_list = [y_valid]\n",
    "# # 假设您的模型已经产生了5步预测\n",
    "# predictions = model.predict(y_valid_list)  # 这应该是一个形状为 (n_samples, 5) 的数组\n",
    "\n",
    "# 初始化指标\n",
    "metrics = {'RMSE': [], 'MAE': [], 'R2Score': [], 'MAPE': []}\n",
    "y_valid = pd.DataFrame(y_valid_list[0])\n",
    "predictions =  pd.DataFrame(closing_price)\n",
    "# 对于每一步预测\n",
    "for step in range(5):\n",
    "    # 计算每个指标\n",
    "    rmse = np.sqrt(mean_squared_error(y_valid.iloc[:, step], predictions.iloc[:, step]))\n",
    "    mae = mean_absolute_error(y_valid.iloc[:, step], predictions.iloc[:, step])\n",
    "    r2 = r2_score(y_valid.iloc[:, step], predictions.iloc[:, step])\n",
    "    mape = np.mean(np.abs((y_valid.iloc[:, step] - predictions.iloc[:, step]) / y_valid.iloc[:, step])) * 100\n",
    "\n",
    "    # 存储指标\n",
    "    metrics['RMSE'].append(rmse)\n",
    "    metrics['MAE'].append(mae)\n",
    "    metrics['R2Score'].append(r2)\n",
    "    metrics['MAPE'].append(mape)\n",
    "\n",
    "# 输出指标\n",
    "print(metrics)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}